{
  "hash": "8c6c021eb319a2083702d8361c78225f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Modeling Diffusion in Volcanic Minerals\nsubtitle: An Explicit Finite Difference Approach\nauthor:\n  - name: Jordan Lubbers\n    affiliations:\n      - name: USGS Alaska Volcano Observatory\n        address: 4230 University Dr, Anchorage Alaska\n\n\n\nformat:\n  html: \n    date-modified: today\n    toc: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-overflow: scroll\n    code-block-border-left: \"#007150\"\n    code-block-background: true\n    code-line-numbers: true\n    code-copy: hover\n    code-tools: true\n    highlight-style: breeze\n    standalone: true\n    warning: false\n    embed-resources: true\n    page-layout: full\n    theme: \n        light: [sandstone, theme_html_light.scss]\n        dark: [slate, theme_html_dark.scss]\n    bibliography: bibliography.bib\n---\n\n::: callout-warning\n## Disclaimer\n\nAny use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.\n:::\n\nBefore we get started some background reading/resources:\n\n-   Diffusion modeling\n    -   [Time Scales of Magmatic Processes from Modeling the Zoning Patterns of Crystals](https://doi.org/10.2138/rmg.2008.69.14)\n    -   [Clocks in Magmatic Rocks](https://doi.org/10.1146/annurev-earth-080320-060708)\n-   Finite Difference\n    -   [Finite Difference Computing with PDEs - A Modern Software Approach](https://hplgit.github.io/fdm-book/doc/pub/book/pdf/fdm-book-4screen.pdf)\n-   Python\n    -   [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n    -   [Intro to Numpy arrays](https://betterprogramming.pub/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d)\n    -   [Scientific Visualization: Python + Matplotlib](https://inria.hal.science/hal-03427242/document)\n\n## Creating our Python virtual environment\n\nTo work on this notebook we will operate in a python [virtual environment](https://realpython.com/python-virtual-environments-a-primer/). You can think of this as a *containerized* way of running specific versions of python and various libraries. This is useful for sharing code that you need to be reproducible in the long-term (e.g., research results). To set it up, we'll use [Anaconda](https://www.anaconda.com/download), terminal window, and an `environment.yml` file. This will install all the requisite libraries and version of python. You can find all the requisite materials [here](https://github.com/jlubbersgeo/diffusion_modeling_walkthrough).\n\n``` bash\ncd path\\to\\environment.yml\nconda env create -f environment.yml\nconda env list # check to make sure everything is installed\n```\n\nRegardless of which IDE you're working in, just choose this virtual environment as the one you want to use: `diffusion_workshop`.\n\n## Fick's Second Law\n\nThe diffusion equation, described by Fick's 2<sup>nd</sup> Law [@fick1855v], explains the way that concentration gradients in minerals change over time. In its most basic form:\n\n$$\n\\frac{\\delta C(x,t)}{\\delta t} = D\\frac{\\delta^2C(x,t)}{\\delta x^2}\n$$\n\n::: {.callout-note collapse=\"true\"}\n## Re-purpose the equations\n\nRight-click on an equation to show the math as `Tex Commands` and copy the formula that created it for use in any text editor that supports $\\LaTeX$.\n:::\n\nThis solution is valid when $D$, the diffusion coefficient, is constant and independent of composition ($C$) or distance ($x$), otherwise the diffusion equation takes the following form:\n\n$$\n\\frac{\\delta C(x,t)}{\\delta t} = \\frac{\\delta D}{\\delta x}\\frac{\\delta C(x,t)}{\\delta x}+\\frac{\\delta^2C(x,t)}{\\delta x^2}\n$$\n\nTo model this behavior we can use the explicit finite difference method, specifically forward in time and centered in space. Below we will walk through both solutions to the diffusion equation. For more information on the mathematics of diffusion, the following are excellent resources:\n\n-   @costa2008time\n-   @crank1979mathematics\n\n## Finite Difference Method\n\nIn brief, to model the diffusion equation using the explicit finite difference method we must:\n\n1.  discretize the domain by creating a grid of distance ($i$) and time ($j$) points\n2.  replace derivatives by finite differences\n3.  formulate a recursive way to calculate the solution at each discrete point\n\nLet's get started by importing the various libraries we'll need. In general, we'll be able to accomplish all the tasks we need with three of the core libraries of the scientific python stack:\n\n1.  [Numpy](https://numpy.org/): fast numerical operations on n-dimensional arrays. Built on top of C code, optimized numpy code is quite quick.\n2.  [Pandas](https://pandas.pydata.org/): for working with and doing statistics on tabular data. The backbone of this is the pandas `DataFrame` that in many ways feels like an excel spreadsheet on steroids.\n3.  [matplotlib](https://matplotlib.org/): Visualization with python. Their documentation says it best: \"Matplotlib makes easy things easy and hard thins possible.\"\n\nWhile there are many fantastic libraries created by open-source contributors, the benefits of minimizing our dependencies are mainly in the following areas:\n\n-   <u>stability</u>: The APIs for these libraries, as they are so popular, does not change that much. This means our code is more robust to version changes.\n-   <u>documentation</u>: Every one of these libraries has fantastic documentation to help you understand how to use them to their full potential.\n-   <u>ubiquity</u>: Anyone working within the scientific python ecosystem will understand what you are talking about when you say you use these libraries.\n-   <u>installation</u>: creating a virtual environment with these three libraries will keep your installation quite lightweight should you choose to distribute it.\n\n::: {#29ccb484 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport uncertainties\nfrom uncertainties import unumpy, ufloat\n\n#-----custom plot appearance for this demo-----\nimport mpl_defaults\n#----------------------------------------------\n\n\nprint(\"VERSIONS USED:\")\nprint(f\"numpy: {np.__version__}\")\nprint(f\"pandas: {pd.__version__}\")\nprint(f\"matplotlib: {matplotlib.__version__}\")\nprint(f\"uncertainties: {uncertainties.__version__}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVERSIONS USED:\nnumpy: 1.26.3\npandas: 2.1.4\nmatplotlib: 3.8.0\nuncertainties: 3.1.7\n```\n:::\n:::\n\n\nBelow is a generalized finite difference grid. The idea behind this is to start from some initial model condition (row 0 below; where diffusion starts from) and iterate forward in time to t $>> 0$, generating a diffusion model curve at each iteration. We can then compare each model curve to our observed analytical transect to find which model best represents it.\n\n::: {#73e70a9b .cell execution_count=2}\n``` {.python .cell-code}\nx = np.linspace(0, 10, 6)\ny = np.linspace(0, 10, 6)\n\nxx, yy = np.meshgrid(x, y)\n\n\nfig, ax = plt.subplots(figsize=(4,4))\nax.set_aspect(1)\nax.plot(\n    xx,\n    yy,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"white\",\n)\nax.minorticks_off()\nax.set_xlabel(\"Distance (i)\")\nax.set_ylabel(\"Time (j)\")\n\ni_idx = 3\n\nfor val, label in zip([-1, 0, 1], [\"i-1,j\", \"i,j\", \"i+1,j\"]):\n    ax.text(xx[:, i_idx + val].mean()-.5, 4.5, f\"C$_{{{label}}}$\")\n\nax.text(xx[:, i_idx].mean()-0.5, 6.5, \"C$_{i,j+1}$\")\n\nax.annotate(\"\", (2, 0), xytext=(4, 0), arrowprops=dict(\n    arrowstyle=\"|-|\",\n    color=\"k\", shrinkA=6, shrinkB=6, mutation_scale=3\n),)\nax.text(2.6, .25, r\"$\\Delta$ x\")\n\nax.annotate(\"\", (2, 0), xytext=(2, 2), arrowprops=dict(\n    arrowstyle=\"|-|\",\n    color=\"k\", shrinkA=6, shrinkB=6, mutation_scale=3\n),)\nax.text(1.2, .9, r\"$\\Delta$ t\", rotation=90)\nax.set_title('Generic Finite Difference Grid', loc='left', y=1.05,fontsize = 14)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-3-output-1.png){width=367 height=395}\n:::\n:::\n\n\n### Constant D solution\n\nBelow we walk through some basic calculus and algebra to show how to discretize some solutions to the diffusion equation. We will start with the basics.\n\n$$\n\\frac{\\delta C}{\\delta t} = D\\frac{\\delta^2C}{\\delta x^2}\n$$\n\n$$\n\\frac{\\delta C}{\\delta x} = S\n$$\n\n$$\n\\frac{\\delta C}{\\delta t} = D\\frac{\\delta S}{\\delta x}\n$$\n\nNow we use $j$ to denote steps in time and $i$ to denote steps in space.\n\n$$\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = D\\frac{S_{i+1,j}-S_{i,j}}{\\Delta x}\n$$\n\n<center>since $S = \\frac{\\delta C}{\\delta x} = \\frac{C_{i} - C_{i-1}}{\\Delta x}$</center>\n\n$$\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = D\\left[\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}-\\frac{C_{i,j}-C_{i-1,j}}{\\Delta x}\\right]\\frac{1}{\\Delta x}\n$$\n\n$$\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = D\\frac{C_{i+1,j}-2C_{i,j}+C_{i-1,j}}{\\Delta x^2}\n$$\n\n::: {.callout-tip title=\"Final Solution\" icon=\"false\"}\n$$\n{C_{i,j+1} = C_{i,j}+\\frac{D\\Delta t}{\\Delta x^2}\\left[C_{i+1,j}-2C_{i,j}+C_{i-1,j}\\right]}\n$$\n:::\n\nThis explains how the concentration of a point in space ($i$) changes with time ($j$) and we see that, importantly, the concentration of any point is determined by the concentrations of the points around it.\n\n### Concentration Dependent D Solution\n\nThis is very similar to the constant D solution, with a couple added derivatives that pertain to a changing D with distance and concentration.\n\n$$\n\\frac{\\delta C}{\\delta t} = \\frac{\\delta D}{\\delta x}\\frac{\\delta C}{\\delta x}+D\\frac{\\delta^2C}{\\delta x^2}\n$$\n\n<center>Again, let $\\frac{\\delta C}{\\delta x} = S$</center>\n\n$$\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = \\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\frac{S_{i+1,j}-S_{i,j}}{\\Delta x}\n$$\n\n<center>since $S = \\frac{\\delta C}{\\delta x} = \\frac{C_{i} - C_{i-1}}{\\Delta x}$</center>\n\n$$\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = \\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\left[\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}-\\frac{C_{i,j}-C_{i-1,j}}{\\Delta x}\\right]\\frac{1}{\\Delta x}\n$$\n\n$$\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = \\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\left[\\frac{C_{i+1,j}-2C_{i,j}+C_{i-1,j}}{\\Delta x^2}\\right]\n$$\n\n::: {.callout-tip title=\"Final Solution\" icon=\"false\"}\n$$\nC_{i,j+1} = C_{i,j} + \\Delta t\\left[\\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\left(\\frac{C_{i+1,j}-2C_{i,j}+C_{i-1,j}}{\\Delta x^2}\\right)\\right]\n$$\n:::\n\nGreat! With these two solutions, we now have a way to model diffusive equilibration in most mineral - element systems!\n\n### Numerical Stability\n\nA key limitation of the explicit finite difference method is that it has the potential to become numerically unstable. This is determined by whether or not the Courant condition is fulfilled. For the diffusion equation in 1D, the Courant condition can be defined as:\n\n$$\nr = \\frac{D\\Delta t}{\\Delta x^2} < 0.5\n$$\n\nNote that for 2D diffusion this condition changes to .25 and for 3D diffusion it reduces even further to .125.\n\nIn modeling diffusion of cations in natural minerals, we are of course limited by a few things:\n\n-   the value of the diffusion coefficient, $D$, is set based on the mineral/element system of interest and the temperature we are modeling at.\n-   the $\\Delta x$ of our model is set based on our analytical resolution.\n\nUltimately, both of these aspects put a limit on the $\\Delta t$ of our model if we want it to be numerically stable. This then suggests that every mineral/element system has a temporal limit on how large of a time step can be modeled. For example, over the same x-grid, slow diffusing elements must have either a larger $\\Delta t$ or smaller $\\Delta x$ than fast diffusing elements to still be numerically stable. Furthermore, our $D$ values and analytical resolution ($\\Delta x$) determine the lower limit we can model diffusion at. A good read on this is found in @bradshaw2017analytical. In brief, the shortest timescale that can be accurately estimated within 20% for a given spatial resolution ($x$) and diffusion coefficient ($D$) is:\n\n$$\nt_{20} = [8.06\\times 10^{-21}x^2]D^{-1}\n$$\n\nwhere $x$ is in $\\mu m$, and $D$ is in $\\frac{\\mu m^2}{s}$.\n\n## Implementation\n\nWith a way to discretize the diffusion equation and an understanding of the limits of its numerical stability we are now able to begin some basic modeling! Conceptually this consists of\n\n1.  Start with an initial profile\n\n::: {#f315c09a .cell execution_count=3}\n``` {.python .cell-code}\nresolution = 5  # um\n\nC = np.full(20, 300)\nC[C.shape[0] // 2:] = 50\n\ndistance = np.arange(0, C.shape[0]) * resolution\n\nfig, ax = plt.subplots(figsize=(4, 4))\nax.plot(distance, C, marker=\"o\", mfc=\"whitesmoke\", mec=\"C0\")\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Concentration\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-4-output-1.png){width=395 height=395}\n:::\n:::\n\n\n2.  create a 1D timegrid to iterate over\n\n::: {#a139615c .cell execution_count=4}\n``` {.python .cell-code}\n# Set up a time grid with some options\n# The end result is a timegrid where each value\n# is in seconds spaced by a user defined dt\n\n\nsinyear = 60 * 60 * 24 * 365.25\ntenthsofyear = sinyear / 10\ndays = sinyear / 365.25\nmonths = sinyear / 12\nhours = sinyear / 8760\n\ntimestep = \"years\"\niterations = 1e4\n\n\nif timestep == \"days\":\n    step = days\nelif timestep == \"months\":\n    step = months\nelif timestep == \"hours\":\n    step = hours\nelif timestep == \"tenths\":\n    step = tenthsofyear\nelif timestep == \"years\":\n    step = sinyear\n# create a time grid that starts at 0\n# goes to n iterations and is spaced by\n# the desired step.\ntimegrid = np.arange(0, iterations * step + 1, step)\ndx = distance[1] - distance[0]\ndt = timegrid[1] - timegrid[0]\n\nprint(f\"you have {timegrid.shape[0]} points in your timegrid\")\nprint(f\"that are spaced by {dt} s\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nyou have 10001 points in your timegrid\nthat are spaced by 31557600.0 s\n```\n:::\n:::\n\n\n3.  apply the discretized diffusion equation at each point in the timegrid to the data from the previous iteration\n4.  save the results of each iteration for later use\n\nWe'll start with a double \"`for` loop\" approach. This is easier to read and conceptualize, but at a cost to performance. Let's generate an initial profile, set some parameters, and forward model diffusion over our timegrid:\n\n::: {#fdb68b97 .cell execution_count=5}\n``` {.python .cell-code}\n# conditions for calculating diffusivity of element in mineral\n# Sr in amphibole from Brabander and Giletti 1995\nDo = 4.9 * 10**-8  # pre exponential constant\nE = 260e3  # activation energy\nT_K = 850 + 273.15  # K\nR = 8.314  # J/molK\nD = (Do * np.exp(-E / (R * T_K))) * 1e12  # um/s\n\nr = (D * dt) / dx**2  # constant\n\n# number of points in space and time\nni, nj = distance.shape[0], timegrid.shape[0]\n\ncurves = np.empty((nj, ni))  # container for model curves at each timestep\n\n\ncurves[0, :] = C.copy()  # initial profile\n\nfor j in range(0, nj - 1):  # time\n    for i in range(1, ni - 1):  # space\n        curves[j + 1, i] = curves[j, i] + r * (\n            curves[j, i - 1] - 2 * curves[j, i] + curves[j, i + 1]\n        )  # inner points\n        curves[j + 1, 0] = C[0]  # fix left point\n        curves[j + 1, -1] = C[-1]  # fix right point\n```\n:::\n\n\nVisualize the results:\n\n::: {#5a94f7e7 .cell execution_count=6}\n``` {.python .cell-code}\nplot_iterations = [10, 50, 100, 250]\n\n\nfig, ax = plt.subplots(\n    1,\n    2,\n    figsize=(8,4),\n    layout=None,\n)\nax[1].remove()\nax[1] = fig.add_subplot(1, 2, 2, projection=\"3d\")\n\n\nxx, yy = np.meshgrid(distance, np.arange(0, timegrid.shape[0]))\n\nmax_iter = plot_iterations[-1]\n\nax[0].plot(distance, C, c=\"k\", label=\"initial\")\nax[1].plot_surface(\n    xx[:max_iter], yy[:max_iter], \n    curves[:max_iter], \n    antialiased=False, \n    cmap=\"viridis\"\n)\n\nfor iteration in plot_iterations:\n\n    ax[0].plot(\n        distance, curves[iteration, :],\n        marker=\"o\", \n        label=f\"iteration {iteration}\"\n    )\n\n    ax[1].plot(\n        distance,\n        curves[iteration],\n        zs=yy[iteration],\n        marker=\"o\",\n        ms=4,\n        lw=1,\n        ls=\"--\",\n        zdir=\"y\",\n        zorder=10,\n    )\nax[0].legend(loc=\"upper right\")\nax[0].set_xlabel(r\"Distance ($\\mu$m)\")\nax[0].set_ylabel(\"Concentration\")\n\nax[1].set_facecolor(\"w\")\nax[1].view_init(25, -70, 0)\nax[1].set_box_aspect(aspect=None, zoom=0.8)\nax[1].set_xlabel(\"Distance\", fontsize=10)\nax[1].set_ylabel(\"iterations\", fontsize=10, labelpad=5)\nax[1].set_zlabel(\"Concentration\", fontsize=10)\nax[1].set_title(\"Finite difference model space\", fontsize=16, y=0.95)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-7-output-1.png){width=765 height=395}\n:::\n:::\n\n\nWe did it! While this is a totally valid approach to implementing the discretized version of the diffusion equation and can be considered a \"scalar\" approach to the problem, this commits one of the pseudo-sins of programming: an excessive `for` loop. With a little cleverness in thinking about our data structures (e.g., the Numpy `ndarray`), we can vectorize the solution such that there is only one `for` loop: the one that iterates through time.\n\nConsider our finite difference grid from before. We will now display it with our diffusion model data:\n\n::: {#4e752641 .cell execution_count=7}\n``` {.python .cell-code}\nxx, yy = np.meshgrid(distance, timegrid[:10])\nidx = 10\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.plot(\n    xx,\n    yy,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"white\",\n)\nax.minorticks_off()\nax.set_xlabel(\"Distance (i)\")\nax.set_ylabel(\"Time (j)\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-8-output-1.png){width=491 height=491}\n:::\n:::\n\n\nNow, let's take the same 1D array of concentration values at a given timestep and index them in three different ways such that they are the same length, but all start and stop at different points:\n\n``` python\nC[1:ni-1] #Ci\nC[0:ni-2] #Ci-1\nC[2:ni]   #Ci+1\n```\n\nBelow this is shown by the colored lines. They are plotted at different timesteps for visualization purposes, but you can see that they are now staggered. Because, however, they are all the same shape, if we index them at the same location (red x marks in the plot below) or when we do element-by-element matrix math we can see that we have created the equivalent C<sub>i</sub>, C<sub>i-1</sub>, C<sub>i+1</sub> structure of the scalar approach!\n\n::: {#d364afbd .cell execution_count=8}\n``` {.python .cell-code}\nxx, yy = np.meshgrid(distance, timegrid[:10])\nidx = 10\n\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.plot(xx[0, 1:ni-1], yy[0, 1:ni-1], label=\"C$_i$\")\nax.plot(xx[0, 0: ni - 2], yy[1, 0: ni - 2], label=\"C$_{i-1}$\")\nax.plot(xx[0, 2:ni], yy[2, 2:ni], label=\"C$_{i+1}$\")\nax.plot(\n    xx,\n    yy,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"white\",\n)\n\n\nax.plot(xx[0, 1:ni-1][idx], yy[0, 0], 'rX', label=f\"slice index {idx}\")\nax.plot(xx[0, 0: ni - 2][idx], yy[1, 0], 'rX')\nax.plot(xx[0, 2:ni][idx], yy[2, 0], 'rX')\nfig.legend(loc='right', bbox_to_anchor=(1.3, .9))\nax.minorticks_off()\nax.set_xlabel(\"Distance (i)\")\nax.set_ylabel(\"Time (j)\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-9-output-1.png){width=633 height=491}\n:::\n:::\n\n\nLet's implement this for our diffusion model:\n\n::: {#b12aea9e .cell execution_count=9}\n``` {.python .cell-code}\nc = np.zeros(ni)\n# this will eventually be the previous iteration, but we start it at\n# our initial profile\nc_n = C.copy()\n\ncurves2 = np.zeros((nj, ni))\ncurves2[0, :] = C.copy()  # initial profile\n\nfor j in range(0, nj - 1):\n    curves2[j + 1, 1: ni - 1] = curves2[j, 1: ni - 1] + r * (\n        curves2[j, 0: ni - 2] - 2 * curves2[j, 1: ni - 1] + curves2[j, 2:ni]\n    )\n    curves2[j + 1, 0] = C[0]  # fix left point\n    curves2[j + 1, -1] = C[-1]  # fix right point\n```\n:::\n\n\nUsing some jupyter magic commands to time code blocks, we see that there is a sizeable performance boost to the vectorized approach. This only gets exaggerated as the solution to the diffusion equation you are modeling becomes more complicated (e.g., non constant D value, solution for plagioclase, diffusion in multiple dimension).\n\nScalar approach:\n\n::: {#61dcf907 .cell execution_count=10}\n``` {.python .cell-code}\n%%timeit\nfor j in range(0,nj-1): # time\n        for i in range(1,ni-1): # space\n            curves[j+1,i] = curves[j,i] + r*(curves[j,i-1] - 2*curves[j,i] \\\n             + curves[j,i+1])\n            curves[j+1,0] = C[0] # fix left point\n            curves[j+1,-1] = C[-1] # fix right point\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n229 ms ± 4.95 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n```\n:::\n:::\n\n\nVectorized approach:\n\n::: {#7bc08483 .cell execution_count=11}\n``` {.python .cell-code}\n%%timeit\nfor j in range(0,nj-1):\n    curves2[j+1,1 : ni - 1] = curves2[j,1 : ni - 1] + r * (curves2[j,0 : ni - 2] \\\n        - 2 * curves2[j,1 : ni - 1] + curves2[j,2:ni])\n    curves2[j+1,0] = C[0] # fix left point\n    curves2[j+1,-1] = C[-1] # fix right point\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n51.4 ms ± 419 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\nWe confirm that they are doing the exact samething:\n\n::: {#140c581f .cell execution_count=12}\n``` {.python .cell-code}\nplot_iteration = 50\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(distance, C, marker=\"o\", mfc=\"whitesmoke\", mec=\"C0\", label=\"initial\")\nax.plot(distance, curves2[plot_iteration, :], lw=3, label=\"double for loop\")\nax.plot(distance, curves[plot_iteration, :], ls=\"--\", c=\"k\", label=\"vectorized\")\n\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Concentration\")\nax.legend(loc=\"upper right\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-13-output-1.png){width=395 height=395}\n:::\n:::\n\n\n## Real World Examples\n\nBelow we'll go through some real world examples to show how you may set this up in your own research. This will discuss the following topics:\n\n-   Fe-Mg in orthopyroxene\n-   Fe-Mg in olivine\n\nIn general we will need a few things:\n\n1.  some observed compositional profiles across a zone boundary\n2.  the rate at which the specified components diffuse through the mineral system\n3.  some decent estimate from which the mineral composition was when it crystallized\n\n### Fe-Mg in orthopyroxene\n\nThe interdiffusion coefficient for Fe-Mg in orthopyroxene was experimentally determined by @dohmen2016fe. For diffusion parallel to the c-axis and for compositions with $0.09 < X_{Fe} < 0.5$:\n\n$$\nD_{Fe-Mg} = 1.12\\times 10^{-6}{f_{O_2}}^{0.053\\pm 0.027}(10^{X_{Fe} - 0.09})\\exp{\\left[\\frac{-308\\pm 23}{RT}\\right]}\n$$\n\nwhere D is in $\\frac{m^2}{s}$, $f_{O_2}$ is in $Pa$, and the activation energy is in $kJ$. For compositions $X_{Fe} < 0.09$ there is minimal dependence on $f_{O_2}$:\n\n$$\nD_{Fe-Mg} = 1.66 \\times 10^{-4}exp\\left[\\frac{-377\\pm30}{RT}\\right]\n$$\n\nDiffusion parallel to the a-axis is 3.5 times smaller than that parallel to the c-axis. Diffusion parallel to the b-axis is assumed to be the same as the c-axis. Let's get started by loading in some data from @ruth2021petrological:\n\n::: {#68dd45e9 .cell execution_count=13}\n``` {.python .cell-code}\npx_data = pd.read_excel(r\".\\data\\test_data.xlsx\", sheet_name=\"pyroxene\")\npx_data.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>Mg_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0000</td>\n      <td>74.491134</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2123</td>\n      <td>75.050209</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.4246</td>\n      <td>75.713827</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.6369</td>\n      <td>76.228272</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.8493</td>\n      <td>76.583086</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#9816d83a .cell execution_count=14}\n``` {.python .cell-code}\nobs_color = \"C7\"\n\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(\"x\", \"Mg_num\", data=px_data, c=obs_color)\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Mg #\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-15-output-1.png){width=395 height=395}\n:::\n:::\n\n\nNow we need to establish some model parameters:\n\n-   T\n-   $f_{O_2}$\n-   crystallographic axis\n\n::: {#922032a9 .cell execution_count=15}\n``` {.python .cell-code}\nT_K = 970 + 273.15\nlogfo2 = -10.32423762\nfo2 = 10**logfo2\nX_Fe = 0.27\n\n\nD0 = 1.12e-6 * fo2**0.053 * 10 ** (X_Fe - 0.09)\n\nEa = 308e3\n\n\ndef diffusivity(D0, Ea, T):\n    \"\"\"calculate the diffusion coefficient according to an \n    arrhenius relationship\n\n\n    Args:\n        D0 (array-like): pre-exponential constant (m^2/s)\n        Ea (array-like): activation energy (J)\n        T (array-like): temperature (K)\n\n    Returns:\n        D (array-like): Diffusion coefficient (m^2/s)\n    \"\"\"\n\n    R = 8.314  # J/Kmol\n    D = D0 * np.exp(-Ea / (R * T))\n\n    return D\n\n\nDc = diffusivity(D0, Ea, T_K) * 1e12\nDa = Dc / 3.5\n```\n:::\n\n\nTime to create some initial boundary conditions. For this we will assume a simple step function that assumes melt (and crystal) chemistry changes instantaneous relative to growth. We're going to create a little helper function here that allows us to create an \"n\" stepped profile by specifying the starting (left), stopping (right) values, and their respective locations:\n\nDefine the function:\n\n::: {#23e38c94 .cell execution_count=16}\n`````````` {.python .cell-code}\ndef create_stepped_profile(\n    dist, step_start, step_stop, step_left, step_middle, step_right\n):\n    \"\"\"Create a stepped profile (1D array) where the height, width, \n    and number of steps are user specified\n\n    Args:\n        dist (array-like): 1D array corresponding to the distance \n        along the measured profile\n        step_start (list): list of `dist` values where each \n        step function should start\n        step_stop (list): list of `dist` values where each \n        step function should stop\n        step_left (list): list of values that correspond to \n        the concentration on the left\n        side of the step function\n        step_middle (list): list of values that correspond \n        to the concentration in the middle of\n        the step function\n        step_right (list): list of values that correspond to \n        the concentration on the right\n        side of the step function\n\n    Returns:\n        stepped_profile : 1D array that has step functions \n        described by `step_start`,`step_stop`,\n        `step_left`, `step_middle`, `step_right`.\n    \"\"\"\n\n    stepped_profile = np.zeros(dist.shape[0])\n    step_begin_idxs = []\n    step_end_idxs = []\n\n    dx = dist[1] - dist[0]\n\n    for i in range(len(step_start)):\n        stepstart = step_start[i] - np.min(dist)\n        step_begin = stepstart\n        step_begin_idx = int(step_begin / dx)\n        step_begin_idxs.append(step_begin_idx)\n\n        stepstop = step_stop[i] - np.min(dist)\n        step_end = stepstop\n        step_end_idx = int(step_end / dx)\n        step_end_idxs.append(step_end_idx)\n\n    for i in range(len(step_start)):\n        if i == 0:\n            # first step function\n            stepped_profile[: step_begin_idxs[i]] = step_left[i]\n            stepped_profile[step_begin_idxs[i]\n                : step_end_idxs[i]] = step_middle[i]\n            stepped_profile[step_end_idxs[i]:] = step_right[i]\n        else:\n            # first step function\n            stepped_profile[step_end_idxs[i - 1]\n                : step_begin_idxs[i]] = step_left[i]\n            stepped_profile[step_begin_idxs[i]\n                : step_end_idxs[i]] = step_middle[i]\n            stepped_profile[step_end_idxs[i]:] = step_right[i]\n\n    return stepped_profile\n``````````\n:::\n\n\nUse the function:\n\n::: {#edceb4ea .cell execution_count=17}\n``` {.python .cell-code}\nstep_start = [25.87]\nstep_stop = [90]\nstep_left = [76.06]\nstep_middle = [69.47]\nstep_right = [69.5]\n\n\ninitial_profile = create_stepped_profile(\n    px_data[\"x\"], step_start=step_start, \n    step_stop=step_stop, step_left=step_left, \n    step_middle=step_middle, \n    step_right=step_right)\n\npx_data['initial_profile'] = initial_profile\n\n\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(\"x\", \"Mg_num\", data=px_data, c=obs_color, label='observed')\nax.plot(\"x\", \"initial_profile\", data=px_data, c='k', label='initial')\nax.set_xlabel(r'Distance ($\\mu$m)')\nax.set_ylabel('Mg #')\nax.legend(loc='upper right')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-18-output-1.png){width=395 height=395}\n:::\n:::\n\n\nNow we create a timegrid. Again, let's create a function because we'll be doing this a lot:\n\n::: {#0a66e2fc .cell execution_count=18}\n``` {.python .cell-code}\ndef get_tgrid(iterations, timestep):\n    \"\"\"\n    generating a time grid for the diffusion model to iterate over\n\n    Parameters\n    ----------\n    iterations : int\n        The number of total iterations you want the model to be\n    timestep : string\n        how to space the time grid. Options are \"hours\", \"days\", \n        \"months\", \"tenths\",\"years\". The time grid will be spaced \n        by the amount of seconds in the specified unit effectively\n        making a \"dt\"\n\n    Returns\n    -------\n    t : ndarray\n        time grid that starts at 0, is spaced by the number of \n        seconds in the specified timestep, and is n-iterations in shape.\n\n    \"\"\"\n\n    sinyear = 60 * 60 * 24 * 365.25\n    tenthsofyear = sinyear / 10\n    days = sinyear / 365.25\n    months = sinyear / 12\n    hours = sinyear / 8760\n\n    if timestep == \"days\":\n        step = days\n    elif timestep == \"months\":\n        step = months\n    elif timestep == \"hours\":\n        step = hours\n    elif timestep == \"tenths\":\n        step = tenthsofyear\n    elif timestep == \"years\":\n        step = sinyear\n    # create a time grid that starts at 0\n    # goes to n iterations and is spaced by\n    # the desired step.\n    t = np.arange(0, iterations * step + 1, step)\n    return t\n```\n:::\n\n\nAnd apply the function:\n\n::: {#9324a990 .cell execution_count=19}\n``` {.python .cell-code}\ntimegrid = get_tgrid(1e5, \"days\")  # about 11.5 years spaced by hours\n```\n:::\n\n\nNow we're ready to forward model diffusion. And again, you guessed it, we're going to create a function. This will be built such that it is able to input generic inputs to be used for any mineral - element combo that follows Fick's 2<sup>nd</sup> Law where the D value is constant:\n\nDefine the function:\n\n::: {#aa43b4c4 .cell execution_count=20}\n``` {.python .cell-code}\ndef FickFD_constant(x, timegrid, diff_coef, init_prof, left_side=\"closed\"):\n    \"\"\"\n    Forward model diffusion in minerals according to Fick's 2nd Law with a\n    constant diffusion coefficient\n\n\n    Args:\n        x (array-like): distance profile\n        timegrid (array-like): array of time values to iterate through. Output\n        of get_timegrid()\n        diff_coef (array-like): diffusion coefficient in um^2/s. \n        init_prof (array-like): profile representing model starting condition\n        left_side (str, optional): left side boundary condition. If 'closed'\n        then the left side is stationary. If 'open' left most point allowed to \n        diffuse Defaults to 'closed'.\n\n    Raises:\n        Exception: if numerically unstable an error will be thrown\n\n    Returns:\n        curves (array-like): a (timegrid,x) shape array of diffusion curves\n        where each row in the array represents a diffusion curve at a discrete\n        timestep. \n    \"\"\"\n\n    ni = x.shape[0]\n    nj = timegrid.shape[0]\n\n    curves = np.empty((nj, ni))\n    curves[0, :] = init_prof.copy()  # initial profile\n\n    dt = timegrid[1] - timegrid[0]\n    dx = x[1] - x[0]  # assume all x points are evenly spaced\n\n    r = (diff_coef * dt) / dx**2  # constant\n\n    if r >= 0.5:\n        raise Exception(\n            \"You do not have numerical stability, please adjust your \\\n            timegrid accordingly. Remember D * dt / dx**2 must be < 0.5\"\n        )\n\n    else:\n\n        for j in range(0, nj - 1):\n            curves[j + 1, 1 : ni - 1] = curves[j, 1 : ni - 1] + r * (\n                curves[j, 0 : ni - 2] - 2 * curves[j, 1 : ni - 1] + curves[j, 2:ni]\n            )\n            if left_side == \"closed\":\n\n                curves[j + 1, 0] = init_prof[0]  # fix left point\n            elif left_side == \"open\":\n\n                curves[j + 1, 0] = curves[j, 0] + r * (\n                    curves[j, 1] - 2 * curves[j, 0] + curves[j, 1]\n                )  # let left point diffuse\n\n            else:\n                raise Exception(\n                    \"Please choose either 'open' or 'closed' for the \\\n                    left side boundary condition\"\n                )\n\n            curves[j + 1, -1] = init_prof[-1]  # fix right point\n\n    return curves\n```\n:::\n\n\nApply the function:\n\n::: {#a1efdd45 .cell execution_count=21}\n``` {.python .cell-code}\nmodel_curves = FickFD_constant(\n    x=px_data[\"x\"],\n    timegrid=timegrid,\n    diff_coef=Dc,\n    init_prof=initial_profile,\n    left_side=\"closed\",\n)\n```\n:::\n\n\nVisualize the results:\n\n::: {#f8d4ab48 .cell execution_count=22}\n``` {.python .cell-code}\nplot_iterations = [\n    10,\n    100,\n    1000,\n    10000,\n]\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(px_data[\"x\"], initial_profile, c=\"k\", label=\"initial\")\nfor iteration in plot_iterations:\n\n    ax.plot(px_data[\"x\"], model_curves[iteration, :], label=f\"iteration {iteration}\")\nax.legend(loc=\"upper right\")\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Concentration\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-23-output-1.png){width=395 height=395}\n:::\n:::\n\n\nFinding the best fit to the observed data can be done by comparing each model curve to the observed data, finding an overall misfit between the two curves, and looking for the minimum misfit. There are a couple metrics to do this by and they'll all probably converge on the same answer, but we'll use the $\\chi ^2$, which can be defined as:\n\n$$\n\\chi^2_j = \\sum_{i=1}^{n_i} \\frac{(O_{i,j} - E_{i,j})^2}{E_{i,j}}\n$$\n\nwhere $O_i$ is a given spot, $i$ in the diffusion model at time $j$, and $E_i$ is the measured data at that point in the distance grid.\n\nDefine the function:\n\n::: {#230ec9cb .cell execution_count=23}\n``` {.python .cell-code}\n# fitting the model using chi squared\ndef fit_model(te, curves, metric=\"chi\"):\n    \"\"\"\n    Find the best fit timestep for the diffusion model that matches the\n    observed data. Uses a standard chi-squared goodness of fit test.\n\n    Parameters\n    ----------\n    te : ndarray\n        the observed (measured) trace element profile in the plagioclase\n    curves : ndarray\n        array that is t.shape[0] x distance.shape[0] and pertains to a \n        diffusion curve for each timestep in the model.\n\n    Returns\n    -------\n    bf_time : int\n       the best fit iteration of the model. Can be plotted as follows:\n\n           fig,ax = plt.subplots()\n           ax.plot(dist,curves[bf_time,:])\n\n    \"\"\"\n    if type(te) == pd.Series:\n        te = np.array(te)\n\n    if metric == \"chi\":\n\n        # sum chi2 value for all curves\n        chi2 = abs(np.sum((curves - te[None, :]) ** 2 / (te[None, :]), axis=1))\n\n        # find the minimum value\n        chi2_min = np.min(chi2)\n\n        # find where in the array it is (e.g., it's position)\n        fit_idx = np.argwhere(chi2 == chi2_min)\n\n        # Get that array index\n        fit_idx = fit_idx[0].item()\n\n        # add one because python starts counting at 0\n        bf_time = fit_idx + 1\n\n        return bf_time, chi2\n    elif metric == \"rmse\":\n        rmse = np.sqrt(np.sum((curves - te[None, :]) ** 2, axis=1) / curves.shape[1])\n\n        rmse_min = np.min(rmse)\n\n        fit_idx = np.argwhere(rmse == rmse_min)\n\n        # Get that array index\n        fit_idx = fit_idx[0].item()\n\n        # add one because python starts counting at 0\n        bf_time = fit_idx + 1\n\n        return bf_time, rmse\n```\n:::\n\n\nApply the function:\n\n::: {#ef122bbe .cell execution_count=24}\n``` {.python .cell-code}\nbest_fit_rmse, rmse_values = fit_model(px_data[\"Mg_num\"], model_curves, metric=\"rmse\")\nbest_fit_chi2, chi2_values = fit_model(px_data[\"Mg_num\"], model_curves, metric=\"chi\")\n\nexcel_best_fit = 1602\npx_data[f\"best_fit_model\"] = model_curves[best_fit_rmse, :]\n\nfig, ax = plt.subplots(figsize = (4,4))\n\ndt = timegrid[1] - timegrid[0]\n\nsec_to_day = 60 * 60 * 24\n\nax.plot(timegrid / sec_to_day, chi2_values, lw=2, label=r\"$\\chi ^2$\")\nax.plot(timegrid / sec_to_day, rmse_values, lw=2, label=\"RMSE\")\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\n    \"time (days)\",\n)\nax.set_ylabel(\n    \"misfit\",\n)\nax.legend(loc=\"lower left\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-25-output-1.png){width=395 height=395}\n:::\n:::\n\n\nVisualize the overall model results:\n\n::: {#396bf79d .cell execution_count=25}\n``` {.python .cell-code}\nbf_color = \"C1\"\nexcel_color = \"C8\"\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\nax[0].plot(\"x\", \"initial_profile\", data=px_data, c=\"k\", label=\"initial\")\nax[0].plot(\"x\", \"Mg_num\", data=px_data, label=\"observed\")\nax[0].plot(\n    \"x\",\n    \"best_fit_model\",\n    data=px_data,\n    label=f\"best fit: {best_fit_rmse} days\",\n    c=bf_color,\n)\nax[0].plot(\n    px_data[\"x\"],\n    model_curves[excel_best_fit, :],\n    c=excel_color,\n    ls=\"--\",\n    label=f\"Excel fit: {excel_best_fit} days\",\n)\nax[0].legend(loc=\"upper right\")\nax[0].set_xlabel(r\"Distance ($\\mu$m)\")\nax[0].set_ylabel(\"Concentration\")\n\ndt = timegrid[1] - timegrid[0]\n\nsec_to_day = 60 * 60 * 24\n\nax[1].plot(\n    timegrid / sec_to_day,\n    chi2_values,\n    \"-k\",\n    lw=2,\n)\n\n# vertical line at best fit value\nax[1].axvline(\n    best_fit_chi2,\n    color=bf_color,\n    label=fr\"best fit: {best_fit_rmse} days @ {int(T_K - 273.15)}$^{{\\circ}}$C\",\n),\nax[1].axvline(\n    excel_best_fit,\n    color=excel_color,\n    ls=\"--\",\n    label=fr\"best fit excel: {excel_best_fit} days @ {int(T_K - 273.15)}$^{{\\circ}}$C\",\n),\nax[1].set_xlabel(\n    \"time (days)\",\n)\nax[1].set_ylabel(\n    r\"$\\sum{\\chi^2} $\",\n)\nax[1].set_xscale(\"log\")\nax[1].legend(\n    loc=\"best\",\n)\nax[1].set_yscale(\"log\")\n\nfig.suptitle(\"1947-2_pyr27_BSE-1\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-26-output-1.png){width=779 height=395}\n:::\n:::\n\n\n### Uncertainties\n\nQuantifying uncertainties in any model is a critical task that helps with their accurate interpretation and diffusion models are no different. The main source of uncertainty in diffusion models are those induced by uncertainties in model temperature and parameters that go into calculating the diffusion coefficient. There are a couple ways to go about this:\n\n-   classical error propagation\n-   monte carlo estimation\n\nThere is also the uncertainty associated with the observed data, itself, but we'll deal with those later.\n\nWe'll start with a classical error propagation approach. Suppose variables x, y, z are measured with uncertainties $\\sigma _x$, $\\sigma_y$, and $\\sigma _z$, and used to compute the function $q(x,y,z)$. If uncertainties are independent and random, the uncertainty in $q$ is [@taylor2022error]:\n\n$$\n\\sigma _q = \\sqrt{{(\\frac{\\delta q}{\\delta x}\\sigma_x)}^2 + {(\\frac{\\delta q}{\\delta y}\\sigma_y)}^2 + {(\\frac{\\delta q}{\\delta z}\\sigma_z)}^2 }\n$$\n\nApplied to the Arrhenius relationship used to calculate diffusion coefficients:\n\n$$\nD = D_0\\exp(\\frac{-E}{RT})\n$$\n\nThe uncertainty in our diffusion coefficient is then:\n\n$$\n\\sigma _D = \\sqrt{{(\\frac{\\delta D}{\\delta D_0}\\sigma _{D_0})}^2 + {(\\frac{\\delta D}{\\delta E}\\sigma _E)}^2 + {(\\frac{\\delta D}{\\delta T}\\sigma _T)}^2 }\n$$\n\nSkipping some algebra and taking each derivative ultimately yields:\n\n$$\n\\sigma _D = \\sqrt{{(\\exp[\\frac{-E}{RT}]\\sigma _{D_0})}^2 + {(\\frac{-D_0\\exp[\\frac{-E}{RT}]}{RT}\\sigma _E)}^2 + {(\\frac{D_0\\exp[\\frac{-E}{RT}]E}{RT^2}\\sigma _T)}^2 }\n$$\n\nWith Fe-Mg diffusion rates in orthopyroxene, the uncertainty in D<sub>0</sub> itself is basically due to the uncertainty $f_{O_2}$ measurements:\n\n$$\nD_0 = (10^{X_{Fe}-0.09}) 1.12\\times 10^{-6}{f_{O_2}}^{0.053\\pm 0.027}\n$$\n\nFollowing the above general error propagation logic, the uncertainty in this term can then be written as:\n\n$$\n\\sigma f_{0_2} = \\frac{\\delta f_{0_2}}{\\delta x}\\sigma _x\n$$\n\nTaking this derivative, and adding in the constants for the D<sub>0</sub> term, our uncertainty in the D<sub>0</sub> is then:\n\n$$\n\\sigma _{D_0} = 1.12\\times 10^{-6}\\times 10^{X_{Fe} - 0.09}\\ln (f_{O_2}){f_{O_2}}^{0.053} 0.027\n$$\n\n::: {#5a2b2886 .cell execution_count=26}\n``` {.python .cell-code}\nsigma_D0 = 1.12e-6 * 10 ** (X_Fe - 0.09) * (fo2**0.053 * np.log(fo2) * 0.027)\nsigma_Ea = 23e3\nsigma_T = 30\nR = 8.314\n\nd_term = (np.exp(-Ea / (R * T_K)) * sigma_D0) ** 2\ne_term = (-D0 * np.exp(-Ea / (R * T_K)) * sigma_Ea / (R * T_K)) ** 2\nT_term = (D0 * np.exp(-Ea / (R * T_K)) * Ea * sigma_T / (R * T_K**2)) ** 2\n\nsigma_Dc = np.sqrt(d_term + e_term + T_term)\nprint(f\"D: {Dc/1e12}\\nstd dev: {sigma_Dc}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nD: 5.495802398029777e-20\nstd dev: 1.3328011987124054e-19\n```\n:::\n:::\n\n\nThat was kind of a pain. And a lot of calculus. Fortunately, there is a standard libary included in `scipy` installs: [`uncertainties`](https://pythonhosted.org/uncertainties/index.html). This will allow us to easily propagate our errors and display them. To accomplish the above calculus and computation we can simply redefine some of our variables to include their uncertainties:\n\n::: {#498bd0d6 .cell execution_count=27}\n``` {.python .cell-code}\nfo2_exp = ufloat(0.053, 0.027)\nfo2_term = fo2**fo2_exp\n\nD0 = 1.12e-6 * fo2_term * 10 ** (X_Fe - 0.09)\nEa = ufloat(308e3, 23e3)\nT_K = ufloat(970 + 273.15, 30)\n\nD_new = D0 * unumpy.exp(-Ea / (8.314 * T_K))\nunc_factor = D_new.std_dev / D_new.nominal_value\nprint(\n    f\"D: {D_new.nominal_value}\\nstd dev: {D_new.std_dev}\\nrelative std \\\n    dev: {int(100 * unc_factor)}%\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nD: 5.495802398029777e-20\nstd dev: 1.3328011987124056e-19\nrelative std     dev: 242%\n```\n:::\n:::\n\n\nNow for the fine print. Our classical approach to error propagation is largely based on linear approximations. What does this *mean*? From the `uncertainties` package documentation:\n\n> The standard deviations and nominal values calculated by this package are thus meaningful approximations as long as uncertainties are “small”. A more precise version of this constraint is that the final calculated functions must have precise linear expansions in the region where the probability distribution of their variables is the largest. Mathematically, this means that the linear terms of the final calculated functions around the nominal values of their variables should be much larger than the remaining higher-order terms over the region of significant probability (because such higher-order contributions are neglected). <br> <br> For example, calculating `x*10` with `x = 5±3` gives a perfect result since the calculated function is linear. So does `umath.atan(umath.tan(x))` for `x = 0±1`, since only the final function counts (not an intermediate function like tan()). <br> <br> Another example is `sin(0+/-0.01)`, for which uncertainties yields a meaningful standard deviation since the sine is quite linear over `0±0.01`. However, `cos(0+/-0.01)`, yields an approximate standard deviation of 0 because it is parabolic around 0 instead of linear; this might not be precise enough for all applications.\n\nA way around this would be to implement a [Monte Carlo](https://en.wikipedia.org/wiki/Monte_Carlo_method) approach. In brief, this will compute the diffusion coefficient many times, but each time the values that contain uncertainties are randomly selected from their probability distribution (mean, standard deviation). This looks something like the following:\n\n::: {#92591496 .cell execution_count=28}\n``` {.python .cell-code}\nn_iterations = 10000\nD_mc = diffusivity(\n    1.12e-6\n    * fo2 ** np.random.normal(fo2_exp.nominal_value, fo2_exp.std_dev, n_iterations)\n    * 10 ** (X_Fe - 0.09),\n    np.random.normal(Ea.nominal_value, Ea.std_dev, n_iterations),\n    np.random.normal(T_K.nominal_value, T_K.std_dev),\n)\nlnD_mc = np.log(D_mc)\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\n\nax[0].hist(D_mc, bins=50)\nax[0].set_yscale(\"log\")\nax[0].set_xlabel(\"D\")\nax[1].hist(lnD_mc, bins=50)\nax[1].set_xlabel(r\"$\\ln{(D)}$\")\nfor a in ax:\n    mpl_defaults.left_bottom_axes(a)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-29-output-1.png){width=779 height=299}\n:::\n:::\n\n\nIn looking at the distribution of D values generated from the Monet Carlo simulation, we see that the distribution is highly log-normal. While we *can* take the standard deviation of this distribution, the reality that ${\\sim}$ 68% of values are within 1 standard deviation of the mean only applies to normal distributions. We should therefore try to make our distribution of D values as normal as possible. In this case we can take the natural log of D values (a clue here is that Arrhenius relationships have $\\exp$ in the function) to transform them to resemble a normal distribution. Once we have a normal distribution, we can take the mean and standard deviation. It is important to note, however, that these values are in the transformed units!! So what we must then do is back transform those values into \"real\" values...in this case $\\ln(\\frac{\\mu m^2}{s}) \\rightarrow (\\frac{\\mu m^2}{s})$. We do this by appling the `np.exp` function.\n\n::: {#645678c2 .cell execution_count=29}\n``` {.python .cell-code}\nlnD_mc_mean = np.mean(lnD_mc)\nlnD_mc_std = np.std(lnD_mc)\n\n# back transform into normal units\nD_mc_mean = np.exp(lnD_mc_mean)\nD_mc_lower_bound = np.exp(lnD_mc_mean - lnD_mc_std)\nD_mc_upper_bound = np.exp(lnD_mc_mean + lnD_mc_std)\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\n\nax[0].hist(D_mc, bins=50)\nax[0].axvline(D_mc_mean, c=\"C1\")\nax[0].axvline(D_mc_lower_bound, c=\"C1\", ls=\"--\")\nax[0].axvline(D_mc_upper_bound, c=\"C1\", ls=\"--\")\nax[0].set_yscale(\"log\")\n\n\naxins = ax[0].inset_axes(\n    [0.2, 0.6, 0.3, 0.3],\n    xlim=(-1e-19,1.3*D_mc_upper_bound), ylim=ax[0].get_ylim(),\n\n)\n\n\naxins.hist(D_mc,bins = 50,zorder = 0)\naxins.axvline(D_mc_mean, c=\"C1\")\naxins.axvline(D_mc_lower_bound, c=\"C1\", ls=\"--\")\naxins.axvline(D_mc_upper_bound, c=\"C1\", ls=\"--\")\naxins.set_yscale(\"log\")\nax[0].indicate_inset_zoom(axins, edgecolor=\"black\",zorder = 1)\naxins.set_yticks([])\naxins.set_xticks([D_mc_lower_bound,D_mc_mean,D_mc_upper_bound])\n\naxins.set_xticklabels([f\"{val:.2E}\" for val in [D_mc_lower_bound,D_mc_mean,D_mc_upper_bound]],rotation = 90,fontsize = 4)\nfor spine in ['top','bottom','left','right']:\n    axins.spines[spine].set_linewidth(1)\n\nmpl_defaults.left_bottom_axes(axins)\n\nax[0].set_xlabel(\"D\")\n\nax[1].hist(lnD_mc, bins=50)\nax[1].axvline(lnD_mc_mean, c=\"C1\")\nax[1].axvline(lnD_mc_mean + lnD_mc_std, c=\"C1\", ls=\"--\")\nax[1].axvline(lnD_mc_mean - lnD_mc_std, c=\"C1\", ls=\"--\")\nax[1].set_xlabel(r\"$\\ln{(D)}$\")\nfor a in ax:\n    mpl_defaults.left_bottom_axes(a)\n\n\nax[0].set_title('Back transformed uncertainties on D',fontsize = 12)\nax[1].set_title(r'$\\mu \\pm \\sigma$ for $\\ln{(D)}$',loc = 'center',fontsize = 12)\n\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-30-output-1.png){width=779 height=299}\n:::\n:::\n\n\nOur uncertainties in \"regular\" units are asymmetric! This is where classical linear error propagation theory has led us astray. Rather than thinking about our timescales in standard deviations, then, it might be more useful to think about this in confidence limits. We can find lower and upper timescale confidence limits relative to the mean best fit time and then apply it to our model:\n\n::: {#5b8f0e96 .cell execution_count=30}\n``` {.python .cell-code}\n# difference of upper bound relative to mean\nupper_conf_limit = abs(D_mc_upper_bound - D_mc_mean) / (D_mc_mean)\n# difference of lower bound relative to mean\nlower_conf_limit = abs(D_mc_lower_bound - D_mc_mean) / D_mc_mean\n\n\nprint(f\"Your model best fit is {best_fit_rmse:.2E} days\")\nprint(f\"The lower confidence limit is {best_fit_rmse*lower_conf_limit:.2} days\")\nprint(f\"The upper confidence limit is {best_fit_rmse*upper_conf_limit:.2} days\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nYour model best fit is 1.60E+03 days\nThe lower confidence limit is 1.4e+03 days\nThe upper confidence limit is 1.4e+04 days\n```\n:::\n:::\n\n\nHere, we have 68% confidence that the calculated $D$ value is between the upper and lower limits. This is commonly referred to as a confidence interval. A 95% confidence interval would be created by going 2 standard deviations away from the mean in $ln(D)$ space rather than 1 like shown above:\n\n``` python\nlnD_mc_std = np.std(lnD_mc) # 68 % confidence \nlnD_mc_2std = 2*np.std(lnD_mc) # 95% confidence \n```\n\n### Fe-Mg in olivine\n\nFe-Mg interdiffusion rates ($\\frac{m^2}{s}$) in olivine along the c-axis can be explained by the following relationship [@chakraborty2010diffusion]. At $f_{O_2}$ \\> $10^{-10}$ Pa:\n\n$$\nD = 10^{-9.21}\\left[\\frac{f_{O_2}}{10^{-7}}\\right]^{\\frac{1}{6}}10^{3(X_{Fe} - 0.1)}\\exp{\\left(\\frac{-201000 + (P-10^{-5})7\\times 10^{-6}}{RT}\\right)}\n$$\n\nWhere T is in Kelvin, P and $f_{O_2}$ are in Pascals, X<sub>Fe</sub> is the mole fraction of the fayalite component, and R is the gas constant in J/mol$\\cdot$K (8.314). Diffusion rates along the a and b axes are 6 times slower than along c. This example lends itself nicely to our tutorial because it introduces an implementation of the solution to the diffusion equation where the diffusion coefficient is dependendent on the composition of the mineral (see above for refresher). Having gone through much of the workflow in the pyroxene demo we are ready to load in some data. This is from Lynn et al., (*in press Bulletin of Volcanology*).\n\n::: {#6c1d169b .cell execution_count=31}\n``` {.python .cell-code}\n# this is how you load in MATLAB matrices\nfrom scipy.io import loadmat\n\n# Fo profile\nol_Fo = loadmat(r\".\\data\\Fo_epma.mat\")\nol_Fo = ol_Fo[\"Fo_epma\"].flatten() / 100\n\n# uncertainty on Fo\nol_err = loadmat(r\".\\data\\err.mat\")\nol_err = ol_err[\"err\"].flatten() / 100\n\n# CaO data\nol_cao = loadmat(r\".\\data\\CaO.mat\")\nol_cao = ol_cao[\"CaO\"].flatten()\n\n# initial profile\nol_Fo_init = loadmat(r\".\\data\\Fo_init.mat\")\nol_Fo_init = ol_Fo_init[\"Fo_init\"].flatten() / 100\n\n# distance profile\nol_dist = loadmat(r\".\\data\\x.mat\")\nol_dist = np.flip(ol_dist[\"x\"].flatten())\n\n# combine them all into one DataFrame\nol_data = pd.DataFrame(\n    {\"Fo\": ol_Fo, \"Fo_err\": ol_err, \"CaO\": ol_cao,\n        \"Fo_init\": ol_Fo_init, \"x\": ol_dist}\n)\nol_data.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fo</th>\n      <th>Fo_err</th>\n      <th>CaO</th>\n      <th>Fo_init</th>\n      <th>x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.881510</td>\n      <td>0.001</td>\n      <td>0.2382</td>\n      <td>0.882</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.881638</td>\n      <td>0.001</td>\n      <td>0.2242</td>\n      <td>0.882</td>\n      <td>11.8424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.882790</td>\n      <td>0.001</td>\n      <td>0.2269</td>\n      <td>0.882</td>\n      <td>23.9281</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.881857</td>\n      <td>0.001</td>\n      <td>0.2342</td>\n      <td>0.882</td>\n      <td>36.0695</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.879441</td>\n      <td>0.001</td>\n      <td>0.2200</td>\n      <td>0.882</td>\n      <td>48.0509</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nPlot it up!\n\n::: {#e063dcae .cell execution_count=32}\n``` {.python .cell-code}\nfig, ax = plt.subplots(2, 1, figsize=(4, 8))\n\nax[0].errorbar(\n    x=\"x\",\n    y=\"Fo\",\n    yerr=\"Fo_err\",\n    data=ol_data,\n    marker=\"o\",\n    ms=4,\n    ls=\"\",\n    mfc=\"white\",\n    mec=\"C0\",\n    label=\"observed\",\n)\n\nax[0].plot(\"x\", \"Fo_init\", data=ol_data, c=\"black\", label=\"initial\")\nax[0].legend(loc=\"lower left\")\nax[0].set_ylabel(\"X$_{Fo}$\")\n\nax[1].plot(\n    \"x\",\n    \"CaO\",\n    data=ol_data,\n    marker=\"o\",\n    ls=\"\",\n    ms=4,\n    mfc=\"white\",\n    mec=\"C1\",\n    label=\"observed\",\n)\nax[1].legend(loc=\"upper left\")\nax[1].set_ylabel(\"CaO (wt%)\")\nax[1].set_xlabel(r\"Distance ($\\mu$m)\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-33-output-1.png){width=395 height=779}\n:::\n:::\n\n\nCalculate the diffusion coefficient:\n\nDefine the function:\n\n::: {#9a576a31 .cell execution_count=33}\n``` {.python .cell-code}\ndef olivine_diffusivity(X_Fo, pressure, fo2, temperature, species=\"fe-mg\"):\n    \"\"\"_summary_\n\n    Args:\n        X_Fo (array-like): mol fraction forsterite\n        pressure (scalar): pressure of crystallization in pascals\n        fo2 (scalar): oxygen fugacity of crystallization in pascals\n        temperature (scalar): temperature of crystallization in pascals\n        species (str, optional): diffusing species. Currently only supports \n        \"fe-mg\". Defaults to \"fe-mg\".\n\n    Returns:\n        Dc, Da, Db : Diffusion coefficent for each crystallographic axis. \n        To find the diffusion coefficient across a given traverse. \n        If alpha, beta, gamma are the angle of the traverse to the a, b, \n        and c axis respectively:\n\n        \n        D_traverse = Da*np.cos(np.deg2rad(alpha))**2+ \\\n            Db*np.cos(np.deg2rad(beta))**2+ Dc*np.cos(np.deg2rad(gamma))**2\n\n\n    \"\"\"\n    X_Fe = np.array(1 - X_Fo)\n    if species == \"fe-mg\":\n\n        Dc = (\n            10**-9.21\n            * (fo2 / 1e-7) ** (1 / 6)\n            * 10 ** (3 * (X_Fe - 0.1))\n            * np.exp(-(201e3 + (pressure - 1e5) * 7e-6) / (8.314 * temperature))\n            * 1e12\n        )\n        Da = Dc / 6\n        Db = Dc / 6\n\n    return Dc, Da, Db\n```\n:::\n\n\nApply the function:\n\n::: {#c085a5ed .cell execution_count=34}\n``` {.python .cell-code}\n# parameters for diffusion coefficient\nT_K = 1200 + 273.15  # Temperature in K\nfo2 = (10**-8.2) * 10**5  # oxygen fugacity in Pa\nP = 42000000  # pressure in Pa\n\n# crystallographic orientation\nalpha = 17  # in degrees, a axis to traverse angle\nbeta = 73  # in degrees, b axis to traverse angle\ngamma = 91  # in degrees, c axis to traverse angle\n\n\n\nDc, Da, Db = olivine_diffusivity(\n    X_Fo=ol_data[\"Fo\"].values, pressure=P, fo2=fo2, temperature=T_K\n)\nD_traverse = (\n    Da * np.cos(np.deg2rad(alpha)) ** 2\n    + Db * np.cos(np.deg2rad(beta)) ** 2\n    + Dc * np.cos(np.deg2rad(gamma)) ** 2\n)\n```\n:::\n\n\nApply the compositionally dependent D value solution to our timegrid:\n\nDefine the function:\n\n::: {#c0e65e90 .cell execution_count=35}\n``` {.python .cell-code}\ndef FickFD_comp_dependent(\n    x,\n    timegrid,\n    init_prof,\n    pressure,\n    fo2,\n    temperature,\n    alpha,\n    beta,\n    gamma,\n    left_side=\"closed\",\n    right_side=\"closed\",\n):\n    \"\"\"\n    Forward model diffusion for olivine according to Fick's 2nd Law with a\n    diffusion coefficient that is dependent on composition. Because the diffusion\n    coefficient needs to be calculated at each iteration, this will calculate the \n    diffusion coefficient for you based off the fo2, temperature, and transect \n    orientation relative to the a, b, and c axes. \n\n\n    Args:\n        x (array-like): distance profile\n        timegrid (array-like): array of time values to iterate through. Output\n        of get_timegrid()\n        init_prof (array-like): profile representing model starting condition\n        pressure (scalar): _description_\n        fo2 (scalar): oxygen fugacity in pascals\n        temperature (scalar): temperature in Kelvin\n        alpha (scalar): angle to a-axis in degrees\n        beta (scalar): angle to b-axis in degrees\n        gamma (scalar): angle to c-axis in degrees\n        left_side (str, optional): left side boundary condition. If 'closed'\n        then the left side is stationary. If 'open' left most point allowed to \n        diffuse Defaults to 'closed'.\n        right_side (str, optional): right side boundary condition. If 'closed'\n        then the right side is stationary. If 'open' right most point allowed to \n        diffuse Defaults to 'closed'.\n\n    Raises:\n        Exception: error for not being numerically stable\n        Exception: error for not specifying boundary conditions correctly\n\n    Returns:\n        curves (array-like): a (timegrid,x) shape array of diffusion curves\n        where each row in the array represents a diffusion curve at a discrete\n        timestep. \n    \"\"\"\n\n    ni = x.shape[0]\n    nj = timegrid.shape[0]\n    if np.any(init_prof > 1):\n        init_prof = init_prof / 100\n\n    curves = np.empty((nj, ni))\n    curves[0, :] = init_prof.copy()  # initial profile\n\n    dt = timegrid[1] - timegrid[0]\n    dx = x[1] - x[0]  # assume all x points are evenly spaced\n\n    Dc, Da, Db = olivine_diffusivity(\n        X_Fo=init_prof, pressure=pressure, fo2=fo2, temperature=temperature\n    )\n\n    r = (Dc * dt) / dx**2  # constant\n\n    if np.any(r >= 0.5):\n        raise Exception(\n            \"You do not have numerical stability, please adjust your timegrid \\\n            accordingly. Remember D * dt / dx**2 must be < 0.5\"\n        )\n\n    else:\n\n        for j in range(0, nj - 1):\n\n            Dc, Da, Db = olivine_diffusivity(\n                X_Fo=curves[j, :], pressure=pressure, fo2=fo2, temperature=temperature\n            )\n            D = (\n                Da * np.cos(np.deg2rad(alpha)) ** 2\n                + Db * np.cos(np.deg2rad(beta)) ** 2\n                + Dc * np.cos(np.deg2rad(gamma)) ** 2\n            )\n\n            # D = diff_coef*10**(3*(0.9-curves[j,:])) #adjust D for composition\n\n            curves[j + 1, 1 : ni - 1] = (\n                curves[j, 1 : ni - 1]\n                + dt\n                / dx**2\n                * ((D[2:ni] - D[1 : ni - 1]))\n                * ((curves[j, 2:ni] - curves[j, 1 : ni - 1]))\n                + D[1 : ni - 1]\n                * dt\n                * (\n                    (curves[j, 2:ni] - 2 * curves[j, 1 : ni - 1] + curves[j, : ni - 2])\n                    / dx**2\n                )\n            )\n\n            if left_side == \"closed\":\n\n                curves[j + 1, 0] = init_prof[0]  # fix left point\n\n            elif left_side == \"open\":\n                curves[j + 1, 0] = (\n                    curves[j, 0]\n                    + dt / dx**2 * ((D[1] - D[0])) * ((curves[j, 1] - curves[j, 0]))\n                    + D[0]\n                    * dt\n                    * ((curves[j, 1] - 2 * curves[j, 0] + curves[j, 1]) / dx**2)\n                )\n\n            if right_side == \"closed\":\n\n                curves[j + 1, -1] = init_prof[-1]  # fix left point\n\n            elif right_side == \"open\":\n\n                curves[j + 1, -1] = (\n                    curves[j, -1]\n                    + dt / dx**2 * ((D[-2] - D[-1])) * ((curves[j, -2] - curves[j, -1]))\n                    + D[-1]\n                    * dt\n                    * ((curves[j, -2] - 2 * curves[j, -1] + curves[j, -2]) / dx**2)\n                )\n\n            else:\n                raise Exception(\n                    \"Please choose either 'open' or 'closed' for the left \\\n                    side boundary condition\"\n                )\n\n    return curves\n```\n:::\n\n\nApply the function:\n\n::: {#039bd623 .cell execution_count=36}\n``` {.python .cell-code}\n# time grid\ntgrid = get_tgrid(1e4, \"hours\")\n\n\n# compositional dependent D solution\nchanging_model_curves = FickFD_comp_dependent(\n    x=ol_data[\"x\"].values,\n    timegrid=tgrid,\n    init_prof=ol_data[\"Fo_init\"].values,\n    pressure=P,\n    fo2=fo2,\n    temperature=T_K,\n    alpha=alpha,\n    beta=beta,\n    gamma=gamma,\n    left_side=\"closed\",\n    right_side=\"closed\",\n)\n```\n:::\n\n\nFind the best fit iteration:\n\n::: {#0e9e0d1a .cell execution_count=37}\n``` {.python .cell-code}\nbest_fit_rmse, rmse_values = fit_model(\n    ol_data[\"Fo\"], changing_model_curves, metric=\"rmse\"\n)\n```\n:::\n\n\nVisualize the results:\n\n::: {#7264dd70 .cell execution_count=38}\n``` {.python .cell-code}\nhours2yrs = 24 * 365.25\nhours2days = 24\nsinday = 60*60*24\nsinyr = hours2yrs * 60 * 60\nfig, ax = plt.subplots(1, 2, figsize=(8, 4), layout=\"constrained\")\n\n\nax[0].errorbar(\n    x=\"x\",\n    y=\"Fo\",\n    yerr=\"Fo_err\",\n    data=ol_data,\n    marker=\"o\",\n    ms=4,\n    ls=\"\",\n    mfc=\"white\",\n    mec=\"C0\",\n    label=\"observed\",\n)\n\n\nax[0].plot(\n    ol_data[\"x\"],\n    changing_model_curves[best_fit_rmse, :],\n    label=f\"best fit: {np.round(best_fit_rmse/hours2days,2)} days\",\n)\n\nax[0].plot(\"x\", \"Fo_init\", data=ol_data, c=\"black\", label='initial')\n\n\nax[0].legend(loc=\"lower left\")\n\nax[0].set_ylabel(\"X$_{Fo}$\", fontsize=20)\nax[0].set_xlabel(r\"Distance ($\\mu$m)\", fontsize=20)\n\n\nax[1].plot(tgrid / sinday, rmse_values, \"k-\")\nax[1].axvline(\n    tgrid[best_fit_rmse] / sinday,\n    c=\"C1\",\n    lw=2,\n    label=f\"best fit: {np.round(best_fit_rmse/hours2days,2)} days\",\n)\nax[1].legend(loc=\"lower right\")\nax[1].set_xlabel(\"model time (days)\", fontsize=20)\nax[1].set_ylabel(\"RMSE\", fontsize=20)\n\nax[0].set_title(\n    fr\"T: {int(T_K - 273.15)} $^{{\\circ}}$C \", loc=\"left\", fontstyle=\"italic\"\n)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-39-output-1.png){width=779 height=395}\n:::\n:::\n\n\n### Sr in plagioclase\n\nSr and Mg flux in plagioclase is a result of two things:\n\n-   diffusion in response to its own gradient\n-   diffusion in response to gradients in $X_{An}$.\n\nThis warrants a special solution to the diffusion equation. A detailed explanation of this can be found in @costa2003diffusion and is expanded on by @dohmen2017chronometry and the Appendix of @lubbers2024constraining. A synopsis:\n\n<center>Remember Fick's 1<sup>st</sup> Law:</center>\n\n$$\nJ = -D\\frac{\\delta C}{\\delta x}\n$$\n\n<center>And Fick's 2<sup>nd</sup> Law:</center>\n\n$$ \n\\frac{\\delta C}{\\delta t} = D\\frac{\\delta ^2C}{\\delta x^2}\n$$\n\n<center>Combining these we get:</center>\n\n$$\n\\frac{\\delta C}{\\delta t} = \\frac{\\delta }{\\delta x}(-J)\n$$\n\n<center>Since for plagioclase:</center>\n\n$$ \nJ = -D_{Sr}\\frac{\\delta C_{Sr}}{\\delta x} + \\frac{D_{Sr}C_{Sr}}{RT}A_{Sr}\\frac{\\delta X_{An}}{\\delta x} \n$$ The final solution to describe how trace elements diffuse in plagioclase with time is:\n\n$$ \n\\frac{\\delta C}{\\delta t} = \\frac{\\delta}{\\delta x}\\left[ D_{Sr}\\frac{\\delta C_{Sr}}{\\delta x} - \\frac{D_{Sr}C_{Sr}}{RT}A_{Sr}\\frac{\\delta X_{An}}{\\delta x}\\right]\n$$\n\nTo help ensure a more stable solution, @dohmen2017chronometry employ another half-space in the $x$ direction:\n\n$$ \nD(x_{i+0.5}) \\frac{\\delta C}{\\delta x}(x_{i+0.5}) \\approx D_{i+0.5}\\frac{C_{i+1}-C_i}{\\Delta x}\n$$\n\nApplying this to the above solution we can then describe how the concentration of Sr in plagioclase evolves with respect to space ($i$) and time ($j$):\n\n::: {.callout-tip icon=\"false\" title=\"Final Solution\"}\n$$\\tiny{\nC_{i,j+1} = \\frac{\\Delta t}{\\Delta x^2}\\left[C_{i+1,j}\\left( D_{i+0.5,j} -  \\frac{D_{i+0.5,j}\\Theta}{2}(An_{i+1} - An_i) \\right) - C_{i,j}\\left(D_{i+0.5,j} + D_{i-0.5,j} +  \\frac{D_{i+0.5,j}\\Theta}{2}(An_{i+1} - An_i) -  \\frac{D_{i-0.5,j}\\Theta}{2}(An_{i} - An_{i-1}) \\right)  +C_{i-1,j}\\left( D_{i-0.5,j} -  \\frac{D_{i-0.5,j}\\Theta}{2}(An_{i} - An_{i-1}) \\right)  \\right]}\n$$\n:::\n\nwhere: $$\n\\Theta = \\frac{A}{RT}\n$$\n\nHere $A$ comes from the relationship that describes how the activity coefficient ($\\gamma$) changes with $X_{An}$ from @dohmen2014predictive: $$\\\n-RTln({\\gamma}) = AX_{An} + B\n$$\n\nCritically, because Sr diffuses significantly faster than the chemical exchange of anorthite and albite, it will equilibrate sufficiently fast such that the An profile can considered stationary. Because the flux of Sr in plagioclase, as shown above, is controlled in part by the An content, the quasi-equilibrium state (i.e., equilibrium state for a given An content) will be heterogeneous. For Sr, that has an activity coefficient that increases with An content, the quasi-equilibrium state will be inversely correlated with An content @dohmen2017chronometry.\n\nAs crystals are open to chemical exchange with the surrounding melt [e.g., infinite reservoir assumption; @crank1979mathematics], the chemical potential of Sr is fixed at the rim. With the understanding that it is not actually the concentration gradient that drives diffusion, but the chemical potential gradient, when the chemical potential at any point in our transect matches that of the rim, we can say we have reached a quasi-equilibrium situation for that An distribution. Formally this can be thought of as $\\frac{\\delta C}{\\delta t} = 0$ and $J_i(x) = J_s = 0$. With respect to our Sr profile, this is explained by: $$\n{C_{Sr}^{eq}}(x) = {C_{Sr}^{0}}\\exp{\\left[\\frac{A_{Sr}}{RT}X_{An}(x)\\right]}\n$$\n\n<center>Where</center>\n\n$$\n{C_{Sr}^{0}} = {C_{Sr}^{rim}}\\exp{\\left[\\frac{-A_{Sr}}{RT}{X_{An}^{rim}}\\right]}\n$$\n\nBelow we'll walk through how to implement the above maths. It relies heavily on the small module [`plag_diff`](https://github.com/jlubbersgeo/diffusion_chronometry/blob/main/plag_diff.py). I strongly consider looking this over and getting familiar with it! It requires two additional packages:\n\n-   [mendeleev](https://mendeleev.readthedocs.io/en/stable/): For working with elemental data (e.g., atmomic masses, atomic numbers)\n-   [statsmodels](https://www.statsmodels.org/stable/index.html): implementation of statistical models in python. In our case regressions.\n-   [tqdm](https://tqdm.github.io/): displaying progress bars in python\n\n::: {#84e4fd3f .cell execution_count=39}\n``` {.python .cell-code}\nimport plag_diff as plag\nfrom tqdm.notebook import tqdm\n```\n:::\n\n\nJust like any function in python, `plag_diff` functions can be utilized with the `help()` function to find out more information:\n\n::: {#3377b216 .cell execution_count=40}\n``` {.python .cell-code}\nhelp(plag.dohmen_kd_calc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHelp on function dohmen_kd_calc in module plag_diff:\n\ndohmen_kd_calc(element, An, sio2_melt, temp)\n    calculate the partition coefficient of either Sr, Mg, or Ba\n            in plagioclase according to the thermodynamic model outlined in\n            Dohmen and Blundy (2014) doi: 10.2475/09.2014.04\n\n            where partition coefficients for Ca and Na are derived from\n            using the LEPR database (Eqs 28a-b).\n\n            Will also calculate A and B parameters required for modeling\n            diffusion of Sr and Mg as outlined in Costa et al. (2003)\n            doi: 10.1016/S0016-7037(02)01345-5 which is effectively\n            a regression of RTln(Kd) vs X_An where A is the slope\n            and B is the intercept.\n\n\n    Args:\n        element (str): element to calculate partition coefficient for\n\n        An (array-like): fraction anorthite content of the plagioclase (X_an)\n\n        sio2_melt (array-like): SiO2 wt% composition of the melt\n\n        temp (array-like): temperature in degrees C\n\n    Returns:\n        dohmen_kd : partition coefficient\n        dohmen_rtlnk : RTln(dohmen_k) in kJ/mol\n        A : slope of regression in dohmen_rtlnk vs X_an space\n        B : intercept of regression in dohmen_rtlnk vs X_an space\n\n```\n:::\n:::\n\n\nWe'll begin by importing some data from @lubbers2024constraining and plotting it up.\n\n::: {#fcaba06d .cell execution_count=41}\n``` {.python .cell-code}\ndata = pd.read_excel(r\".\\data\\test_data.xlsx\",\n                     sheet_name=\"plagioclase\").set_index('grain')\n\n# specify which grain to use\ngrain = \"MQ3\"\n\n# specify which element to model\nelement = \"Sr\"\n\nresolution = 5.0  # um\n\n# for consistent colors throughout\nobs_color = \"#000000\"  # observed data\n# equilibrium data\ndohmen_color = \"#FF1F5B\"\nan_color = \"#0D4A70\"\ninit_color = \"#A0B1BA\"  # initial profile related data\nbf_color = \"#00CD6C\"\n\n\n# the domain you wish to model diffusion over\n# try to keep this untouched but if there are\n# erroneous ends on your data this will clip them\nstart = 0\nstop = 0\n\n\n# unclipped data for a grain\n# distance\ndist_all = np.arange(0, data.loc[grain, :].shape[0]) * resolution\n# measured trace element information\nte_all = data.loc[grain, element].to_numpy()\nte_unc_all = data.loc[grain, \"{}_se\".format(element)].to_numpy()\n# anorthite\nan_all = data.loc[grain, \"An\"].to_numpy()\nif np.unique(an_all > 1)[0] == True:\n    an_all = an_all / 100\n# clipped data. If above start and stop are 0 they\n# will be the same as the unclipped data. This is fine.\nte = te_all[start: len(te_all) - stop]\nte_unc = te_unc_all[start: len(te_all) - stop]\ndist = dist_all[start: len(te_all) - stop]\nan = an_all[start: len(te_all) - stop]\n\n\n# plot observed data\nfig, ax = plt.subplots(figsize=(4, 4))\n# observed profile and subset\nl1, = ax.plot(\n    dist,\n    te,\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    ms=5,\n    mew=0.75,\n    label=element,\n)\nax.fill_between(dist, te + te_unc, te - te_unc, fc=obs_color, alpha=0.2)\n\nax2 = ax.twinx()\nl2, = ax2.plot(\n    dist,\n    an,\n    c=an_color,\n    marker=\"\",\n    mfc=\"w\",\n    mec=an_color,\n    ms=5,\n    mew=0.75,\n    ls='--',\n    label=\"anorthite\",\n)\nax2.tick_params(axis=\"y\", which=\"both\", colors=an_color)\nax2.set_ylabel(\"X$_{An}$\", c=an_color)\n\nax.legend(handles=[l1, l2], fancybox=True, shadow=True)\n# fig.legend(loc=\"best\")\n\nax.set_ylabel(\"{} [ppm]\".format(element), c=obs_color)\nax.tick_params(axis=\"y\", which=\"both\", colors=obs_color)\nax.set_xlabel(\"Distance ($\\mu$m)\")\n\nax.text(0, 1.03, 'Core', fontsize=20, transform=ax.transAxes)\nax.text(0.8, 1.03, 'Rim', fontsize=20, transform=ax.transAxes)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-42-output-1.png){width=395 height=395}\n:::\n:::\n\n\nWe then calculate the quasi-equilibrium profile. Later on we will show that no matter how long we run our diffusion model for, the Sr profile will not deviate from the quasi equilibrium situation even though we may be at magmatic temperatures. Below we show:\n\n-   Left: our observed Sr profile with respect to the quasi equilibrium profile\n-   Right: our observed Sr vs X<sub>An</sub> data with respect to the quasi equilibrium Sr vs X<sub>An</sub> data.\n\nWe also plot a curve (black dashed line) for the equilibrium trace element partitioning at our specified temperature and melt composition.\n\n::: {#bb66d5d6 .cell execution_count=42}\n``` {.python .cell-code}\nT = 750 #celsius\nT_K = T + 273.15 #kelvin\nR = 8.314 #J/molK\nsio2_melt = 72 #wt%\n\nRTlngamma, gamma, slope, intercept, stats = plag.dohmen_activity_calc(\n    element, an, T, return_regression_stats=True\n)\n\nkd, rtlnk, A, B = plag.plag_kd_calc(\n        element, an, T, method=\"Dohmen\", sio2_melt=sio2_melt)\n\n# range of anorthite compositions to calculate equilibrium curves\nan_partition = np.linspace(0, 1,101)\n\n# Calculated Mg equilibrium\nkd_eq, rtlnk_eq, A_eq, B_eq = plag.plag_kd_calc(\n    element, an_partition, T, method=\"Dohmen\", sio2_melt=sio2_melt\n)\n\n\nc0 = te[-1] * np.exp(-slope*1000/(R*T_K)*an[-1])\neq_prof = c0 * np.exp(slope*1000/(R*T_K)*an)\n\nEq_solid_ave = te[-1] / kd[-1] * kd_eq\n\n\n\nfig,ax = plt.subplots(1,2,figsize = (8,4),layout = 'constrained')\n\nax[0].plot(\n    dist,\n    te,\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    ms=5,\n    mew=0.75,\n    label=f\"{element} observed\",\n)\nax[0].fill_between(dist, te + te_unc, te - te_unc, fc = obs_color, alpha=0.2)\nax[0].plot(dist,eq_prof,lw = 2, color = dohmen_color, label = 'quasi equilibrium')\nax[0].legend(loc = 'best')\n\nax[1].plot(an_partition, Eq_solid_ave, color='k', ls = '--', zorder = 0, label = 'eq. partitioning')\nax[1].plot(an,eq_prof,marker = 'o',ls = '',mfc = 'none',mec = dohmen_color,label = 'quasi equilibrium',zorder = 0)\ns = ax[1].scatter(an, te, c=dist, ec='k', lw=0.75,label = f'{element} observed')\nfig.colorbar(s, ax=ax[1], label='distance ($\\mu$m)')\nax[1].legend(loc = 'upper right')\n\n\nax[0].set_ylabel(f\"{element} [ppm]\")\nax[0].set_xlabel('Distance ($\\mu$m)')\nax[1].set_xlabel('X$_{An}$')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-43-output-1.png){width=779 height=395}\n:::\n:::\n\n\nNext, we must determine the initial profile. This is probably one of the aspects of plagioclase diffusion modeling that introduces the most uncertainty. The basic premise of this is:\n\n1.  calculate a \"melt equivalent\" profile that based on the observed data. This is simply $C_l = \\frac{C_s}{K_d}$ and represents the effective melt composition in equilibrium with the observed data. We make the assumption that some diffusion has occured between crystallization and eruption, and therefore this melt equivalent profile does NOT represent the melt composition at the time of crystallization.\n2.  To approximate the melt composition at the time of plagioclase formation we take \"melt equivalent\" profile and simplify it back to a series of two or three discrete compositions that are based off changes in the An profile. Becuase the An component in plagioclase can effectively be treated as stationary in this scenario, it offers a good opportunity to view where changes in melt composition are happening. We then back calculate that simplified melt profile into plagioclase compositions that's in equilibrium with it to get our initial profile. An overall caveat of this methodology is that it necessitates that not much diffusion has occurred. If significant diffusion has occurred, creating simplified melt profiles off the observed data will not yield a melt profile that reflects the initial melt evolution during crystallization. We however, don't believe this is the case for our grains, due to the observed positive relationships between Sr and An. In brief, because Sr is compatible in plagioclase, this observed positive relationship generally means that little to no diffusive re-equilibration has occured in plagioclase [e.g., @cooper2014rapid]. Further evidence to suggest that a positive correlation between Sr and X<sub>An</sub> reflects minimal diffusive equilibration is that the quasi equilibrium profile calculated above has a strong negative correlation and as diffusion progresses in the grain from initial profile to quasi equilibrium (shown later) this relationship goes from positive to negative.\n\nIn the case where one is trying to model diffusion for a profile where it is assumed that the profile is close to quasi-equilibrium another method of estimating the initial profile would have to be used (e.g., creating a melt equivalent profile that mimics the shape and magnitude of the An profile changes, creating an initial profile that is effictively a \"mirror\" to the calculated equilibrium profile). More than any other assumption (and this goes for any study that forward models diffusion in plagioclase) the initial profile is probably the one that introduces the most uncertainty and we realize this, however, based on past reviewer comments in previous manuscripts, it was decided this was a sufficient way to go about it as creating an initial profile that is a simplified version of the observed plagioclase proflie (i.e., creating a solid profile step function) implicitly creates the situation whereby the melt profile would be extremely variable to keep the Sr profile the simplified shape. We do not believe we have the petrologic evidence to create such a melt profile and take an Occam's Razor approach in this case: a minimum number of input melt compositions is better.\n\n::: {#4a71cc49 .cell execution_count=43}\n``` {.python .cell-code}\nmelt_equivalent = te / kd\n\nsimple_liquid = plag.create_stepped_profile(\n    dist,\n    step_start=[20],\n    step_stop=[90],\n    step_left=[105],\n    step_middle=[98],\n    step_right=[145],\n)\n\ninitial_profile = simple_liquid * kd\n\nfig, ax = plt.subplots(1, 3, figsize=(9, 3), layout='constrained')\n\nax[0].plot(dist, an, c=an_color, label='X$_{An}$')\nax[0].set_ylabel('X$_{An}$')\n\nax[1].plot(dist, melt_equivalent, color=obs_color,\n           label='obs. melt equivalent')\nax[1].plot(dist, simple_liquid, color=init_color,\n           ls=\"-.\", lw=2, label=\"simple melt equivalent\")\nax[1].legend(loc='upper left')\n\nax[2].plot(\n    dist,\n    te,\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    ms=5,\n    mew=0.75,\n    label=f\"{element} observed\",\n)\nax[2].fill_between(dist, te + te_unc, te - te_unc, fc=obs_color, alpha=0.2)\nax[2].plot(dist, eq_prof, lw=2, color=dohmen_color, label='quasi equilibrium')\nax[2].plot(dist, initial_profile, color=init_color,\n           ls=\"-.\", lw=2, label=\"initial condition\")\nax[2].legend(loc='best')\n\nax[1].set_ylabel(f\"{element} [ppm]\")\nax[2].set_ylabel(f\"{element} [ppm]\")\n\nfig.supxlabel('Distance ($\\mu$m)')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-44-output-1.png){width=875 height=299}\n:::\n:::\n\n\nNow that we have our quasi-equilibrium profile calculated, it is time to create our timegrid, calculate the diffusion coefficient, and implement the special halfspace solution to the diffusion equation outlined above. In `plag_diff` this is easily done by:\n\n::: {#e943ccc8 .cell execution_count=44}\n``` {.python .cell-code}\niterations = int(1 * 1e5)\ntimestep = \"tenths\" #iterate every tenth of a year\n\n\n# creating a time grid that is spaced by years\nt = plag.get_tgrid(iterations, timestep)\n\n#diffusion coefficient for every point in the profile\nD = plag.plag_diffusivity(element, an, T_K)\n\n# call the function that does the modeling ove the above numerical\n# solution\ncurves, best_fit_iteration, chi2_array = plag.diffuse_forward_halfspace(\n        initial_profile=initial_profile,\n        observed_profile=te,\n        timegrid=t,\n        diffusivity_profile=D,\n        an_profile=an,\n        slope=slope,\n        distance_profile=dist,\n        temp=T,\n        boundary=\"infinite observed\",\n        local_minima=True,\n    )\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"22b7537cee56433eb1f82691d1cc1719\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n:::\n\n\nVisualize the results:\n\n::: {#bb74b4de .cell execution_count=45}\n``` {.python .cell-code}\n#conversion factor to turn iterations to years\nmakeyears = 10\n\nfig,ax = plt.subplots(1,2,figsize = (8,4),layout = 'constrained')\ncompare = [makeyears * 1e2, makeyears * 1e3, makeyears * 1e4,]\ncompare_colors = [\"C3\", \"C4\", \"C5\"]\n\n\nax[0].plot(dist, initial_profile, c = init_color, lw=2, label=\"initial profile\")\nax[0].plot(\n    dist,\n    te,\n    label=\"observed\",\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    mew=0.75,\n)\nax[0].fill_between(dist, te + te_unc, te - te_unc,fc = obs_color, alpha=0.2)\nax[0].plot(\n    dist, eq_prof, c=dohmen_color, lw=2, ls = '--', label=\"Equilibrium\",)  # boundary conditions\n\nfor i in range(0, len(compare)):\n    ax[0].plot(\n        dist,\n        curves[int(compare[i])],\n        label=\"t = {:.2E} yrs\".format(compare[i] / makeyears),\n        lw=0.75,\n        color=compare_colors[i],\n    )\n    \n\n\nax[0].plot(dist, curves[best_fit_iteration], \"-\", c=bf_color,\n           mec=\"k\", lw=3, label=\"best fit\")\nh, l = ax[0].get_legend_handles_labels()\nfig.legend(h, l, loc=\"upper left\", ncol=len(h)//2, bbox_to_anchor=(0.1, 1.2))\n\n\n# chi-squared plot\n# convert to days\ntdays = t / (t[1] - t[0])\nx_data = tdays / makeyears\nax[1].plot(\n    x_data,\n    chi2_array,\n    \"-k\",\n    lw=2,\n)\n# vertical line at best fit value\nax[1].axvline(\n    best_fit_iteration / makeyears,\n    color=bf_color,\n    label=\"t = {} yrs\".format(np.round(best_fit_iteration / makeyears, 2)),\n    lw=1,\n    ls=\"--\",\n)\nax[1].plot(x_data[best_fit_iteration], chi2_array[best_fit_iteration], mfc=\"w\",\n        marker=\"o\", ls=\"\", mec=bf_color, mew=1)\nax[1].set_xlabel(\"time (yrs)\", fontsize=16)\nax[1].set_ylabel(\"$\\sum{\\chi^2} $\", fontsize=16)\nax[1].set_xscale(\"log\")\nax[1].legend(loc=\"lower left\", title=\"Best Fit\", prop={\"size\": 10})\nax[1].set_yscale(\"log\")\nax[1].set_xlabel(\"Time (yrs)\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-46-output-1.png){width=779 height=469}\n:::\n:::\n\n\nNext we'll deal with model uncertainties. Here we will randomly vary two things for 1000 iterations to see their impact on our diffusion model:\n\n1.  Temperature: this then changes our A value and diffusion coefficient\n2.  Our analytical profile: This reflects uncertainty in our analyses and how it impacts the diffusion model\n\nFor each iteration we will find a best fit diffusion model to the random analytical profile and save it. We'll then get statistics on this distribution and visualize it.\n\nWhile technically a change in temperature would change our melt equivalent profile and possibly then our choice of initial profile, this would require a manual choosing of initial condition each iteration of the monte carlo, rendering this sort of exercise not possible. So...for this exercise we leave it the same during each iteration.\n\nThe `plag.diffuse_forward_halfspace` function is set up to minimize computation time by being vectorized, however the default is to have the `local_minima` argument set to `True`. This forces it to search over the entire timegrid space and calculate a model curve for each value in the timegrid. While quite quick for 1 diffusion model, when we are trying to do 1000 of them, this can unecessarily increase computation time, especially if the best fit is near the front end of the timegrid. By setting `local_minima = False` the model runs and checks the misfit each iteration. If the misfit is less than the previous iteration the model continues calculating diffusion curves. If the misfit for the current iteration is larger than the previous iteration it stops and marks that as the best fit time. Because we have confirmed above that there are no local minima in our chi-squared vs. time plot, this methodology is safe. Still...This is when you may want to go get a cup of coffee. 1000 iterations can take anywhere from 1-10 minutes. Here we only do 100 to save time in the example.\n\n::: {#998b100e .cell execution_count=46}\n``` {.python .cell-code}\nbest_fits = []\niterations = 100  # for example purposes\n\nfor i in tqdm(range(iterations)):\n    T = np.random.normal(750, 20)\n    RTlngamma, gamma, slope, intercept, stats = plag.dohmen_activity_calc(\n        element, an, T, return_regression_stats=True\n    )\n\n    c, b, c2 = plag.diffuse_forward_halfspace(\n        initial_profile=initial_profile,\n        observed_profile=plag.random_profile(te, te_unc),\n        timegrid=t,\n        diffusivity_profile=plag.plag_diffusivity(\n            element=element, an=an, T_K=T + 273.15\n        ),\n        an_profile=an,\n        slope=slope,\n        distance_profile=dist,\n        temp=T,\n        boundary=\"infinite observed\",\n        local_minima=False,\n    )\n    best_fits.append(b)\n\nbest_fits = np.array(best_fits)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"71f066c7943542eb80c4ad8404d83ffc\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n:::\n\n\nFinally, we visualize the results of the Monte Carlo simulation and make a summary figure that puts it all together.\n\n::: {#6b10377f .cell execution_count=47}\n``` {.python .cell-code}\nfig, ax = plt.subplot_mosaic(\n    [[\"prof\", \"an_prof\"], [\"prof\", \"hist\"]],\n    layout=\"constrained\",\n    height_ratios=[2, 1],\n    width_ratios=[3, 2],\n    figsize=(8, 4),\n)\nfs = 10\nms = 5\n\nax[\"prof\"].plot(dist, initial_profile, init_color, lw=2, label=\"initial profile\")\nax[\"prof\"].plot(\n    dist,\n    te,\n    label=\"observed\",\n    c=obs_color,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    mew=0.75,\n    ms=ms,\n)\nax[\"prof\"].fill_between(dist, te + te_unc, te - te_unc, alpha=0.2)\nax[\"prof\"].plot(\n    dist, curves[best_fit_iteration], \"-\", c=bf_color, mec=\"k\", lw=3, label=\"best fit\"\n)\n\nax[\"prof\"].plot(\n    dist, eq_prof, c=dohmen_color, lw=2, label=\"DB14 quasi eq.\"\n)  # boundary conditions\n\n\nax[\"prof\"].set_xlabel(\"Distance ($\\mu$m)\", fontsize=16)\nax[\"prof\"].set_ylabel(f\"{element} [ppm]\", fontsize=16)\n\n\nfig.legend(loc=\"upper left\", ncol=4, bbox_to_anchor=(0.1, 1.1))\n\nax[\"an_prof\"].plot(dist, an, \"k-\", linewidth=1.5)\nax[\"an_prof\"].set_ylabel(\"X$_{An}$\", fontsize=16)\nax[\"an_prof\"].set_xlabel(\"Distance ($\\mu$m)\", fontsize=12)\n\nax[\"hist\"].hist(\n    best_fits / makeyears,\n    facecolor=\"whitesmoke\",\n    edgecolor=\"k\",\n    linestyle=\"--\",\n)\nax[\"hist\"].plot(\n    best_fits.mean() / makeyears,\n    0,\n    marker=\"o\",\n    mec=\"darkgreen\",\n    mfc=bf_color,\n    mew=1.5,\n    clip_on=False,\n    zorder=10,\n)\n# mpl_defaults.left_bottom_axes(ax[\"hist\"])\nax[\"hist\"].set_xlabel(\"best fit time (yrs)\", fontsize=12)\nax[\"hist\"].set_ylabel(\"counts\", fontsize=12)\n\ntransform = \"log\"\n\nif transform:\n    (\n        transform_mc_results,\n        transform_mean,\n        transform_median,\n        transform_low,\n        transform_high,\n    ) = plag.transform_data(best_fits / makeyears, kind=transform)\n\n    ax[\"prof\"].text(\n        0.05,\n        1.03,\n        \"$t_{{mean}}$ = {} yrs\".format(np.round(transform_mean, 2)),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=fs,\n    )\n    ax[\"prof\"].text(\n        0.55,\n        1.03,\n        \"$t_{{95}} = \\pm$ {} ; {}\".format(\n            np.round(transform_mean - transform_low, 2),\n            np.round(transform_high - transform_mean, 2),\n        ),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=fs,\n    )\nelse:\n    ax[\"prof\"].text(\n        0.05,\n        1.03,\n        \"$t_{{mean}}$ = {} yrs\".format(np.round(best_fits.mean(), 2)),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=10,\n    )\n    ax[\"prof\"].text(\n        0.55,\n        1.03,\n        \"$t_{{95}} = \\pm$ {}\".format(np.round(2 * np.std(best_fits), 2)),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=10,\n    )\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](numerical_modeling_walkthrough_files/figure-html/cell-48-output-1.png){width=779 height=431}\n:::\n:::\n\n\n## References\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "numerical_modeling_walkthrough_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"09cb92f9377f4fa6829321857301aea5\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"0a03a7cdb22743aabf0bb3ff696a39c9\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"11dafb3a43b54ad6875a036ab63d44f8\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"1bd287f1e534412db0f95c327f10bd42\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"22b7537cee56433eb1f82691d1cc1719\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_2a301a6e97194f54979d8a5c5d71db20\",\"IPY_MODEL_ae212465445841a7b279024823134724\",\"IPY_MODEL_4ab6b67a4e6a4cc7a0d2d8a92a85375d\"],\"layout\":\"IPY_MODEL_6f6e474ee5f24cfd9a4b75cf67d7052f\",\"tabbable\":null,\"tooltip\":null}},\"2a301a6e97194f54979d8a5c5d71db20\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_8a638d45b5ad45ca981f9cd2071c51f7\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_f1c329f6f8d1469f9a6920a021468ec5\",\"tabbable\":null,\"tooltip\":null,\"value\":\"100%\"}},\"4ab6b67a4e6a4cc7a0d2d8a92a85375d\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_8642db4d0a3e4634857847c0f33bd1a0\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_9ca90c90dcc549168e25cc20e4bd2c94\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 100001/100001 [00:02&lt;00:00, 41557.25timestep/s]\"}},\"529d697e107f43cd91b58c6db7bcbb86\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_11dafb3a43b54ad6875a036ab63d44f8\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_ac0e7754469e440a9591b42609a6d391\",\"tabbable\":null,\"tooltip\":null,\"value\":\"100%\"}},\"571ad0223cda43c7928db58760f25ad6\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_1bd287f1e534412db0f95c327f10bd42\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_f3fbdab64b80485a9ace5472ede74ea4\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 100/100 [00:58&lt;00:00,  1.62it/s]\"}},\"62d73d9c223a4a03935a61f7e4e531c8\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_09cb92f9377f4fa6829321857301aea5\",\"max\":100,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_a795f86c292340a5a4071cf0ddcaa013\",\"tabbable\":null,\"tooltip\":null,\"value\":100}},\"6f6e474ee5f24cfd9a4b75cf67d7052f\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"71f066c7943542eb80c4ad8404d83ffc\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_529d697e107f43cd91b58c6db7bcbb86\",\"IPY_MODEL_62d73d9c223a4a03935a61f7e4e531c8\",\"IPY_MODEL_571ad0223cda43c7928db58760f25ad6\"],\"layout\":\"IPY_MODEL_be900439428d4bf38e258ba90c090c9c\",\"tabbable\":null,\"tooltip\":null}},\"8642db4d0a3e4634857847c0f33bd1a0\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"8a638d45b5ad45ca981f9cd2071c51f7\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"9ca90c90dcc549168e25cc20e4bd2c94\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"a795f86c292340a5a4071cf0ddcaa013\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"ac0e7754469e440a9591b42609a6d391\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"ae212465445841a7b279024823134724\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_ba4e5af25c2644faaba2f4f07666bf41\",\"max\":100001,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_0a03a7cdb22743aabf0bb3ff696a39c9\",\"tabbable\":null,\"tooltip\":null,\"value\":100001}},\"ba4e5af25c2644faaba2f4f07666bf41\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"be900439428d4bf38e258ba90c090c9c\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"f1c329f6f8d1469f9a6920a021468ec5\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"f3fbdab64b80485a9ace5472ede74ea4\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}