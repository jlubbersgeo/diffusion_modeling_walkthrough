[
  {
    "objectID": "numerical_modeling_walkthrough.html",
    "href": "numerical_modeling_walkthrough.html",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "",
    "text": "Before we get started some background reading/resources:"
  },
  {
    "objectID": "numerical_modeling_walkthrough.html#creating-our-python-virtual-environment",
    "href": "numerical_modeling_walkthrough.html#creating-our-python-virtual-environment",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "Creating our Python virtual environment",
    "text": "Creating our Python virtual environment\nTo work on this notebook we will operate in a python virtual environment. You can think of this as a containerized way of running specific versions of python and various libraries. This is useful for sharing code that you need to be reproducible in the long-term (e.g., research results). To set it up, we’ll use Anaconda, terminal window, and an environment.yml file. This will install all the requisite libraries and version of python.\ncd path\\to\\environment.yml\nconda env create -f environment.yml\nconda env list # check to make sure everything is installed\nRegardless of which IDE you’re working in, just choose this virtual environment as the one you want to use: diffusion_workshop."
  },
  {
    "objectID": "numerical_modeling_walkthrough.html#ficks-second-law",
    "href": "numerical_modeling_walkthrough.html#ficks-second-law",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "Fick’s Second Law",
    "text": "Fick’s Second Law\nThe diffusion equation, described by Fick’s 2nd Law (Fick 1855), explains the way that concentration gradients in minerals change over time. In its most basic form:\n\\[\n\\frac{\\delta C(x,t)}{\\delta t} = D\\frac{\\delta^2C(x,t)}{\\delta x^2}\n\\]\n\n\n\n\n\n\nRe-purpose the equations\n\n\n\n\n\nRight-click on an equation to show the math as Tex Commands and copy the formula that created it for use in any text editor that supports \\(\\LaTeX\\).\n\n\n\nThis solution is valid when \\(D\\), the diffusion coefficient, is constant and independent of composition (\\(C\\)) or distance (\\(x\\)), otherwise the diffusion equation takes the following form:\n\\[\n\\frac{\\delta C(x,t)}{\\delta t} = \\frac{\\delta D}{\\delta x}\\frac{\\delta C(x,t)}{\\delta x}+\\frac{\\delta^2C(x,t)}{\\delta x^2}\n\\]\nTo model this behavior we can use the explicit finite difference method, specifically forward in time and centered in space. Below we will walk through both solutions to the diffusion equation. For more information on the mathematics of diffusion, the following are excellent resources:\n\nFidel Costa, Dohmen, and Chakraborty (2008)\nCrank (1979)"
  },
  {
    "objectID": "numerical_modeling_walkthrough.html#finite-difference-method",
    "href": "numerical_modeling_walkthrough.html#finite-difference-method",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "Finite Difference Method",
    "text": "Finite Difference Method\nIn brief, to model the diffusion equation using the explicit finite difference method we must:\n\ndiscretize the domain by creating a grid of distance (\\(i\\)) and time (\\(j\\)) points\nreplace derivatives by finite differences\nformulate a recursive way to calculate the solution at each discrete point\n\nLet’s get started by importing the various libraries we’ll need. In general, we’ll be able to accomplish all the tasks we need with three of the core libraries of the scientific python stack:\n\nNumpy: fast numerical operations on n-dimensional arrays. Built on top of C code, optimized numpy code is quite quick.\nPandas: for working with and doing statistics on tabular data. The backbone of this is the pandas DataFrame that in many ways feels like an excel spreadsheet on steroids.\nmatplotlib: Visualization with python. Their documentation says it best: “Matplotlib makes easy things easy and hard thins possible.”\n\nWhile there are many fantastic libraries created by open-source contributors, the benefits of minimizing our dependencies are mainly in the following areas:\n\nstability: The APIs for these libraries, as they are so popular, does not change that much. This means our code is more robust to version changes.\ndocumentation: Every one of these libraries has fantastic documentation to help you understand how to use them to their full potential.\nubiquity: Anyone working within the scientific python ecosystem will understand what you are talking about when you say you use these libraries.\ninstallation: creating a virtual environment with these three libraries will keep your installation quite lightweight should you choose to distribute it.\n\n\n\nShow the code\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport uncertainties\nfrom uncertainties import unumpy, ufloat\n\n#-----custom plot appearance for this demo-----\nimport mpl_defaults\n#----------------------------------------------\n\n\nprint(\"VERSIONS USED:\")\nprint(f\"numpy: {np.__version__}\")\nprint(f\"pandas: {pd.__version__}\")\nprint(f\"matplotlib: {matplotlib.__version__}\")\nprint(f\"uncertainties: {uncertainties.__version__}\")\n\n\nVERSIONS USED:\nnumpy: 1.25.2\npandas: 2.0.3\nmatplotlib: 3.8.0\nuncertainties: 3.1.7\n\n\nBelow is a generalized finite difference grid. The idea behind this is to start from some initial model condition (row 0 below; where diffusion starts from) and iterate forward in time to t \\(&gt;&gt; 0\\), generating a diffusion model curve at each iteration. We can then compare each model curve to our observed analytical transect to find which model best represents it.\n\n\nShow the code\nx = np.linspace(0, 10, 6)\ny = np.linspace(0, 10, 6)\n\nxx, yy = np.meshgrid(x, y)\n\n\nfig, ax = plt.subplots(figsize=(4,4))\nax.set_aspect(1)\nax.plot(\n    xx,\n    yy,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"white\",\n)\nax.minorticks_off()\nax.set_xlabel(\"Distance (i)\")\nax.set_ylabel(\"Time (j)\")\n\ni_idx = 3\n\nfor val, label in zip([-1, 0, 1], [\"i-1,j\", \"i,j\", \"i+1,j\"]):\n    ax.text(xx[:, i_idx + val].mean()-.5, 4.5, f\"C$_{{{label}}}$\")\n\nax.text(xx[:, i_idx].mean()-0.5, 6.5, \"C$_{i,j+1}$\")\n\nax.annotate(\"\", (2, 0), xytext=(4, 0), arrowprops=dict(\n    arrowstyle=\"|-|\",\n    color=\"k\", shrinkA=6, shrinkB=6, mutation_scale=3\n),)\nax.text(2.6, .25, r\"$\\Delta$ x\")\n\nax.annotate(\"\", (2, 0), xytext=(2, 2), arrowprops=dict(\n    arrowstyle=\"|-|\",\n    color=\"k\", shrinkA=6, shrinkB=6, mutation_scale=3\n),)\nax.text(1.2, .9, r\"$\\Delta$ t\", rotation=90)\nax.set_title('Generic Finite Difference Grid', loc='left', y=1.05,fontsize = 14)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConstant D solution\nBelow we walk through some basic calculus and algebra to show how to discretize some solutions to the diffusion equation. We will start with the basics.\n\\[\n\\frac{\\delta C}{\\delta t} = D\\frac{\\delta^2C}{\\delta x^2}\n\\]\n\\[\n\\frac{\\delta C}{\\delta x} = S\n\\]\n\\[\n\\frac{\\delta C}{\\delta t} = D\\frac{\\delta S}{\\delta x}\n\\]\nNow we use \\(j\\) to denote steps in time and \\(i\\) to denote steps in space.\n\\[\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = D\\frac{S_{i+1,j}-S_{i,j}}{\\Delta x}\n\\]\n\nsince \\(S = \\frac{\\delta C}{\\delta x} = \\frac{C_{i} - C_{i-1}}{\\Delta x}\\)\n\n\\[\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = D\\left[\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}-\\frac{C_{i,j}-C_{i-1,j}}{\\Delta x}\\right]\\frac{1}{\\Delta x}\n\\]\n\\[\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = D\\frac{C_{i+1,j}-2C_{i,j}+C_{i-1,j}}{\\Delta x^2}\n\\]\n\n\n\n\n\n\nFinal Solution\n\n\n\n\\[\n{C_{i,j+1} = C_{i,j}+\\frac{D\\Delta t}{\\Delta x^2}\\left[C_{i+1,j}-2C_{i,j}+C_{i-1,j}\\right]}\n\\]\n\n\nThis explains how the concentration of a point in space (\\(i\\)) changes with time (\\(j\\)) and we see that, importantly, the concentration of any point is determined by the concentrations of the points around it.\n\n\nConcentration Dependent D Solution\nThis is very similar to the constant D solution, with a couple added derivatives that pertain to a changing D with distance and concentration.\n\\[\n\\frac{\\delta C}{\\delta t} = \\frac{\\delta D}{\\delta x}\\frac{\\delta C}{\\delta x}+D\\frac{\\delta^2C}{\\delta x^2}\n\\]\n\nAgain, let \\(\\frac{\\delta C}{\\delta x} = S\\)\n\n\\[\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = \\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\frac{S_{i+1,j}-S_{i,j}}{\\Delta x}\n\\]\n\nsince \\(S = \\frac{\\delta C}{\\delta x} = \\frac{C_{i} - C_{i-1}}{\\Delta x}\\)\n\n\\[\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = \\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\left[\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}-\\frac{C_{i,j}-C_{i-1,j}}{\\Delta x}\\right]\\frac{1}{\\Delta x}\n\\]\n\\[\n\\frac{C_{i,j+1}-C_{i,j}}{\\Delta t} = \\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\left[\\frac{C_{i+1,j}-2C_{i,j}+C_{i-1,j}}{\\Delta x^2}\\right]\n\\]\n\n\n\n\n\n\nFinal Solution\n\n\n\n\\[\nC_{i,j+1} = C_{i,j} + \\Delta t\\left[\\left(\\frac{D_{i+1,j}-D_{i,j}}{\\Delta x}\\right)\\left(\\frac{C_{i+1,j}-C_{i,j}}{\\Delta x}\\right)+D_i\\left(\\frac{C_{i+1,j}-2C_{i,j}+C_{i-1,j}}{\\Delta x^2}\\right)\\right]\n\\]\n\n\nGreat! With these two solutions, we now have a way to model diffusive equilibration in most mineral - element systems!\n\n\nNumerical Stability\nA key limitation of the explicit finite difference method is that it has the potential to become numerically unstable. This is determined by whether or not the Courant condition is fulfilled. For the diffusion equation in 1D, the Courant condition can be defined as:\n\\[\nr = \\frac{D\\Delta t}{\\Delta x^2} &lt; 0.5\n\\]\nNote that for 2D diffusion this condition changes to .25 and for 3D diffusion it reduces even further to .125.\nIn modeling diffusion of cations in natural minerals, we are of course limited by a few things:\n\nthe value of the diffusion coefficient, \\(D\\), is set based on the mineral/element system of interest and the temperature we are modeling at.\nthe \\(\\Delta x\\) of our model is set based on our analytical resolution.\n\nUltimately, both of these aspects put a limit on the \\(\\Delta t\\) of our model if we want it to be numerically stable. This then suggests that every mineral/element system has a temporal limit on how large of a time step can be modeled. For example, over the same x-grid, slow diffusing elements must have either a larger \\(\\Delta t\\) or smaller \\(\\Delta x\\) than fast diffusing elements to still be numerically stable. Furthermore, our \\(D\\) values and analytical resolution (\\(\\Delta x\\)) determine the lower limit we can model diffusion at. A good read on this is found in Bradshaw and Kent (2017). In brief, the shortest timescale that can be accurately estimated within 20% for a given spatial resolution (\\(x\\)) and diffusion coefficient (\\(D\\)) is:\n\\[\nt_{20} = [8.06\\times 10^{-21}x^2]D^{-1}\n\\]\nwhere \\(x\\) is in \\(\\mu m\\), and \\(D\\) is in \\(\\frac{\\mu m^2}{s}\\)."
  },
  {
    "objectID": "numerical_modeling_walkthrough.html#implementation",
    "href": "numerical_modeling_walkthrough.html#implementation",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "Implementation",
    "text": "Implementation\nWith a way to discretize the diffusion equation and an understanding of the limits of its numerical stability we are now able to begin some basic modeling! Conceptually this consists of\n\nStart with an initial profile\n\n\n\nShow the code\nresolution = 5  # um\n\nC = np.full(20, 300)\nC[C.shape[0] // 2:] = 50\n\ndistance = np.arange(0, C.shape[0]) * resolution\n\nfig, ax = plt.subplots(figsize=(4, 4))\nax.plot(distance, C, marker=\"o\", mfc=\"whitesmoke\", mec=\"C0\")\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Concentration\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\ncreate a 1D timegrid to iterate over\n\n\n\nShow the code\n# Set up a time grid with some options\n# The end result is a timegrid where each value\n# is in seconds spaced by a user defined dt\n\n\nsinyear = 60 * 60 * 24 * 365.25\ntenthsofyear = sinyear / 10\ndays = sinyear / 365.25\nmonths = sinyear / 12\nhours = sinyear / 8760\n\ntimestep = \"years\"\niterations = 1e4\n\n\nif timestep == \"days\":\n    step = days\nelif timestep == \"months\":\n    step = months\nelif timestep == \"hours\":\n    step = hours\nelif timestep == \"tenths\":\n    step = tenthsofyear\nelif timestep == \"years\":\n    step = sinyear\n# create a time grid that starts at 0\n# goes to n iterations and is spaced by\n# the desired step.\ntimegrid = np.arange(0, iterations * step + 1, step)\ndx = distance[1] - distance[0]\ndt = timegrid[1] - timegrid[0]\n\nprint(f\"you have {timegrid.shape[0]} points in your timegrid\")\nprint(f\"that are spaced by {dt} s\")\n\n\nyou have 10001 points in your timegrid\nthat are spaced by 31557600.0 s\n\n\n\napply the discretized diffusion equation at each point in the timegrid to the data from the previous iteration\nsave the results of each iteration for later use\n\nWe’ll start with a double “for loop” approach. This is easier to read and conceptualize, but at a cost to performance. Let’s generate an initial profile, set some parameters, and forward model diffusion over our timegrid:\n\n\nShow the code\n# conditions for calculating diffusivity of element in mineral\n# Sr in amphibole from Brabander and Giletti 1995\nDo = 4.9 * 10**-8  # pre exponential constant\nE = 260e3  # activation energy\nT_K = 850 + 273.15  # K\nR = 8.314  # J/molK\nD = (Do * np.exp(-E / (R * T_K))) * 1e12  # um/s\n\nr = (D * dt) / dx**2  # constant\n\n# number of points in space and time\nni, nj = distance.shape[0], timegrid.shape[0]\n\ncurves = np.empty((nj, ni))  # container for model curves at each timestep\n\n\ncurves[0, :] = C.copy()  # initial profile\n\nfor j in range(0, nj - 1):  # time\n    for i in range(1, ni - 1):  # space\n        curves[j + 1, i] = curves[j, i] + r * (\n            curves[j, i - 1] - 2 * curves[j, i] + curves[j, i + 1]\n        )  # inner points\n        curves[j + 1, 0] = C[0]  # fix left point\n        curves[j + 1, -1] = C[-1]  # fix right point\n\n\nVisualize the results:\n\n\nShow the code\nplot_iterations = [10, 50, 100, 250]\n\n\nfig, ax = plt.subplots(\n    1,\n    2,\n    figsize=(8,4),\n    layout=None,\n)\nax[1].remove()\nax[1] = fig.add_subplot(1, 2, 2, projection=\"3d\")\n\n\nxx, yy = np.meshgrid(distance, np.arange(0, timegrid.shape[0]))\n\nmax_iter = plot_iterations[-1]\n\nax[0].plot(distance, C, c=\"k\", label=\"initial\")\nax[1].plot_surface(\n    xx[:max_iter], yy[:max_iter], \n    curves[:max_iter], \n    antialiased=False, \n    cmap=\"viridis\"\n)\n\nfor iteration in plot_iterations:\n\n    ax[0].plot(\n        distance, curves[iteration, :],\n        marker=\"o\", \n        label=f\"iteration {iteration}\"\n    )\n\n    ax[1].plot(\n        distance,\n        curves[iteration],\n        zs=yy[iteration],\n        marker=\"o\",\n        ms=4,\n        lw=1,\n        ls=\"--\",\n        zdir=\"y\",\n        zorder=10,\n    )\nax[0].legend(loc=\"upper right\")\nax[0].set_xlabel(r\"Distance ($\\mu$m)\")\nax[0].set_ylabel(\"Concentration\")\n\nax[1].set_facecolor(\"w\")\nax[1].view_init(25, -70, 0)\nax[1].set_box_aspect(aspect=None, zoom=0.8)\nax[1].set_xlabel(\"Distance\", fontsize=10)\nax[1].set_ylabel(\"iterations\", fontsize=10, labelpad=5)\nax[1].set_zlabel(\"Concentration\", fontsize=10)\nax[1].set_title(\"Finite difference model space\", fontsize=16, y=0.95)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nWe did it! While this is a totally valid approach to implementing the discretized version of the diffusion equation and can be considered a “scalar” approach to the problem, this commits one of the pseudo-sins of programming: an excessive for loop. With a little cleverness in thinking about our data structures (e.g., the Numpy ndarray), we can vectorize the solution such that there is only one for loop: the one that iterates through time.\nConsider our finite difference grid from before. We will now display it with our diffusion model data:\n\n\nShow the code\nxx, yy = np.meshgrid(distance, timegrid[:10])\nidx = 10\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.plot(\n    xx,\n    yy,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"white\",\n)\nax.minorticks_off()\nax.set_xlabel(\"Distance (i)\")\nax.set_ylabel(\"Time (j)\")\nplt.show()\n\n\n\n\n\n\n\n\n\nNow, let’s take the same 1D array of concentration values at a given timestep and index them in three different ways such that they are the same length, but all start and stop at different points:\nC[1:ni-1] #Ci\nC[0:ni-2] #Ci-1\nC[2:ni]   #Ci+1\nBelow this is shown by the colored lines. They are plotted at different timesteps for visualization purposes, but you can see that they are now staggered. Because, however, they are all the same shape, if we index them at the same location (red x marks in the plot below) or when we do element-by-element matrix math we can see that we have created the equivalent Ci, Ci-1, Ci+1 structure of the scalar approach!\n\n\nShow the code\nxx, yy = np.meshgrid(distance, timegrid[:10])\nidx = 10\n\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.plot(xx[0, 1:ni-1], yy[0, 1:ni-1], label=\"C$_i$\")\nax.plot(xx[0, 0: ni - 2], yy[1, 0: ni - 2], label=\"C$_{i-1}$\")\nax.plot(xx[0, 2:ni], yy[2, 2:ni], label=\"C$_{i+1}$\")\nax.plot(\n    xx,\n    yy,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"white\",\n)\n\n\nax.plot(xx[0, 1:ni-1][idx], yy[0, 0], 'rX', label=f\"slice index {idx}\")\nax.plot(xx[0, 0: ni - 2][idx], yy[1, 0], 'rX')\nax.plot(xx[0, 2:ni][idx], yy[2, 0], 'rX')\nfig.legend(loc='right', bbox_to_anchor=(1.3, .9))\nax.minorticks_off()\nax.set_xlabel(\"Distance (i)\")\nax.set_ylabel(\"Time (j)\")\nplt.show()\n\n\n\n\n\n\n\n\n\nLet’s implement this for our diffusion model:\n\n\nShow the code\nc = np.zeros(ni)\n# this will eventually be the previous iteration, but we start it at\n# our initial profile\nc_n = C.copy()\n\ncurves2 = np.zeros((nj, ni))\ncurves2[0, :] = C.copy()  # initial profile\n\nfor j in range(0, nj - 1):\n    curves2[j + 1, 1: ni - 1] = curves2[j, 1: ni - 1] + r * (\n        curves2[j, 0: ni - 2] - 2 * curves2[j, 1: ni - 1] + curves2[j, 2:ni]\n    )\n    curves2[j + 1, 0] = C[0]  # fix left point\n    curves2[j + 1, -1] = C[-1]  # fix right point\n\n\nUsing some jupyter magic commands to time code blocks, we see that there is a sizeable performance boost to the vectorized approach. This only gets exaggerated as the solution to the diffusion equation you are modeling becomes more complicated (e.g., non constant D value, solution for plagioclase, diffusion in multiple dimension).\nScalar approach:\n\n\nShow the code\n%%timeit\nfor j in range(0,nj-1): # time\n        for i in range(1,ni-1): # space\n            curves[j+1,i] = curves[j,i] + r*(curves[j,i-1] - 2*curves[j,i] \\\n             + curves[j,i+1])\n            curves[j+1,0] = C[0] # fix left point\n            curves[j+1,-1] = C[-1] # fix right point\n\n\n254 ms ± 4.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\nVectorized approach:\n\n\nShow the code\n%%timeit\nfor j in range(0,nj-1):\n    curves2[j+1,1 : ni - 1] = curves2[j,1 : ni - 1] + r * (curves2[j,0 : ni - 2] \\\n        - 2 * curves2[j,1 : ni - 1] + curves2[j,2:ni])\n    curves2[j+1,0] = C[0] # fix left point\n    curves2[j+1,-1] = C[-1] # fix right point\n\n\n50.8 ms ± 265 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nWe confirm that they are doing the exact samething:\n\n\nShow the code\nplot_iteration = 50\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(distance, C, marker=\"o\", mfc=\"whitesmoke\", mec=\"C0\", label=\"initial\")\nax.plot(distance, curves2[plot_iteration, :], lw=3, label=\"double for loop\")\nax.plot(distance, curves[plot_iteration, :], ls=\"--\", c=\"k\", label=\"vectorized\")\n\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Concentration\")\nax.legend(loc=\"upper right\")\n\nplt.show()"
  },
  {
    "objectID": "numerical_modeling_walkthrough.html#real-world-examples",
    "href": "numerical_modeling_walkthrough.html#real-world-examples",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "Real World Examples",
    "text": "Real World Examples\nBelow we’ll go through some real world examples to show how you may set this up in your own research. This will discuss the following topics:\n\nFe-Mg in orthopyroxene\nFe-Mg in olivine\n\nIn general we will need a few things:\n\nsome observed compositional profiles across a zone boundary\nthe rate at which the specified components diffuse through the mineral system\nsome decent estimate from which the mineral composition was when it crystallized\n\n\nFe-Mg in orthopyroxene\nThe interdiffusion coefficient for Fe-Mg in orthopyroxene was experimentally determined by Dohmen et al. (2016). For diffusion parallel to the c-axis and for compositions with \\(0.09 &lt; X_{Fe} &lt; 0.5\\):\n\\[\nD_{Fe-Mg} = 1.12\\times 10^{-6}{f_{O_2}}^{0.053\\pm 0.027}(10^{X_{Fe} - 0.09})\\exp{\\left[\\frac{-308\\pm 23}{RT}\\right]}\n\\]\nwhere D is in \\(\\frac{m^2}{s}\\), \\(f_{O_2}\\) is in \\(Pa\\), and the activation energy is in \\(kJ\\). For compositions \\(X_{Fe} &lt; 0.09\\) there is minimal dependence on \\(f_{O_2}\\):\n\\[\nD_{Fe-Mg} = 1.66 \\times 10^{-4}exp\\left[\\frac{-377\\pm30}{RT}\\right]\n\\]\nDiffusion parallel to the a-axis is 3.5 times smaller than that parallel to the c-axis. Diffusion parallel to the b-axis is assumed to be the same as the c-axis. Let’s get started by loading in some data from Ruth and Costa (2021):\n\n\nShow the code\npx_data = pd.read_excel(r\".\\data\\test_data.xlsx\", sheet_name=\"pyroxene\")\npx_data.head()\n\n\n\n\n\n\n\n\n\n\nx\nMg_num\n\n\n\n\n0\n0.0000\n74.491134\n\n\n1\n0.2123\n75.050209\n\n\n2\n0.4246\n75.713827\n\n\n3\n0.6369\n76.228272\n\n\n4\n0.8493\n76.583086\n\n\n\n\n\n\n\n\n\n\nShow the code\nobs_color = \"C7\"\n\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(\"x\", \"Mg_num\", data=px_data, c=obs_color)\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Mg #\")\nplt.show()\n\n\n\n\n\n\n\n\n\nNow we need to establish some model parameters:\n\nT\n\\(f_{O_2}\\)\ncrystallographic axis\n\n\n\nShow the code\nT_K = 970 + 273.15\nlogfo2 = -10.32423762\nfo2 = 10**logfo2\nX_Fe = 0.27\n\n\nD0 = 1.12e-6 * fo2**0.053 * 10 ** (X_Fe - 0.09)\n\nEa = 308e3\n\n\ndef diffusivity(D0, Ea, T):\n    \"\"\"calculate the diffusion coefficient according to an \n    arrhenius relationship\n\n\n    Args:\n        D0 (array-like): pre-exponential constant (m^2/s)\n        Ea (array-like): activation energy (J)\n        T (array-like): temperature (K)\n\n    Returns:\n        D (array-like): Diffusion coefficient (m^2/s)\n    \"\"\"\n\n    R = 8.314  # J/Kmol\n    D = D0 * np.exp(-Ea / (R * T))\n\n    return D\n\n\nDc = diffusivity(D0, Ea, T_K) * 1e12\nDa = Dc / 3.5\n\n\nTime to create some initial boundary conditions. For this we will assume a simple step function that assumes melt (and crystal) chemistry changes instantaneous relative to growth. We’re going to create a little helper function here that allows us to create an “n” stepped profile by specifying the starting (left), stopping (right) values, and their respective locations:\nDefine the function:\n\n\nShow the code\ndef create_stepped_profile(\n    dist, step_start, step_stop, step_left, step_middle, step_right\n):\n    \"\"\"Create a stepped profile (1D array) where the height, width, \n    and number of steps are user specified\n\n    Args:\n        dist (array-like): 1D array corresponding to the distance \n        along the measured profile\n        step_start (list): list of `dist` values where each \n        step function should start\n        step_stop (list): list of `dist` values where each \n        step function should stop\n        step_left (list): list of values that correspond to \n        the concentration on the left\n        side of the step function\n        step_middle (list): list of values that correspond \n        to the concentration in the middle of\n        the step function\n        step_right (list): list of values that correspond to \n        the concentration on the right\n        side of the step function\n\n    Returns:\n        stepped_profile : 1D array that has step functions \n        described by `step_start`,`step_stop`,\n        `step_left`, `step_middle`, `step_right`.\n    \"\"\"\n\n    stepped_profile = np.zeros(dist.shape[0])\n    step_begin_idxs = []\n    step_end_idxs = []\n\n    dx = dist[1] - dist[0]\n\n    for i in range(len(step_start)):\n        stepstart = step_start[i] - np.min(dist)\n        step_begin = stepstart\n        step_begin_idx = int(step_begin / dx)\n        step_begin_idxs.append(step_begin_idx)\n\n        stepstop = step_stop[i] - np.min(dist)\n        step_end = stepstop\n        step_end_idx = int(step_end / dx)\n        step_end_idxs.append(step_end_idx)\n\n    for i in range(len(step_start)):\n        if i == 0:\n            # first step function\n            stepped_profile[: step_begin_idxs[i]] = step_left[i]\n            stepped_profile[step_begin_idxs[i]\n                : step_end_idxs[i]] = step_middle[i]\n            stepped_profile[step_end_idxs[i]:] = step_right[i]\n        else:\n            # first step function\n            stepped_profile[step_end_idxs[i - 1]\n                : step_begin_idxs[i]] = step_left[i]\n            stepped_profile[step_begin_idxs[i]\n                : step_end_idxs[i]] = step_middle[i]\n            stepped_profile[step_end_idxs[i]:] = step_right[i]\n\n    return stepped_profile\n\n\nUse the function:\n\n\nShow the code\nstep_start = [25.87]\nstep_stop = [90]\nstep_left = [76.06]\nstep_middle = [69.47]\nstep_right = [69.5]\n\n\ninitial_profile = create_stepped_profile(\n    px_data[\"x\"], step_start=step_start, \n    step_stop=step_stop, step_left=step_left, \n    step_middle=step_middle, \n    step_right=step_right)\n\npx_data['initial_profile'] = initial_profile\n\n\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(\"x\", \"Mg_num\", data=px_data, c=obs_color, label='observed')\nax.plot(\"x\", \"initial_profile\", data=px_data, c='k', label='initial')\nax.set_xlabel(r'Distance ($\\mu$m)')\nax.set_ylabel('Mg #')\nax.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\nNow we create a timegrid. Again, let’s create a function because we’ll be doing this a lot:\n\n\nShow the code\ndef get_tgrid(iterations, timestep):\n    \"\"\"\n    generating a time grid for the diffusion model to iterate over\n\n    Parameters\n    ----------\n    iterations : int\n        The number of total iterations you want the model to be\n    timestep : string\n        how to space the time grid. Options are \"hours\", \"days\", \n        \"months\", \"tenths\",\"years\". The time grid will be spaced \n        by the amount of seconds in the specified unit effectively\n        making a \"dt\"\n\n    Returns\n    -------\n    t : ndarray\n        time grid that starts at 0, is spaced by the number of \n        seconds in the specified timestep, and is n-iterations in shape.\n\n    \"\"\"\n\n    sinyear = 60 * 60 * 24 * 365.25\n    tenthsofyear = sinyear / 10\n    days = sinyear / 365.25\n    months = sinyear / 12\n    hours = sinyear / 8760\n\n    if timestep == \"days\":\n        step = days\n    elif timestep == \"months\":\n        step = months\n    elif timestep == \"hours\":\n        step = hours\n    elif timestep == \"tenths\":\n        step = tenthsofyear\n    elif timestep == \"years\":\n        step = sinyear\n    # create a time grid that starts at 0\n    # goes to n iterations and is spaced by\n    # the desired step.\n    t = np.arange(0, iterations * step + 1, step)\n    return t\n\n\nAnd apply the function:\n\n\nShow the code\ntimegrid = get_tgrid(1e5, \"days\")  # about 11.5 years spaced by hours\n\n\nNow we’re ready to forward model diffusion. And again, you guessed it, we’re going to create a function. This will be built such that it is able to input generic inputs to be used for any mineral - element combo that follows Fick’s 2nd Law where the D value is constant:\nDefine the function:\n\n\nShow the code\ndef FickFD_constant(x, timegrid, diff_coef, init_prof, left_side=\"closed\"):\n    \"\"\"\n    Forward model diffusion in minerals according to Fick's 2nd Law with a\n    constant diffusion coefficient\n\n\n    Args:\n        x (array-like): distance profile\n        timegrid (array-like): array of time values to iterate through. Output\n        of get_timegrid()\n        diff_coef (array-like): diffusion coefficient in um^2/s. \n        init_prof (array-like): profile representing model starting condition\n        left_side (str, optional): left side boundary condition. If 'closed'\n        then the left side is stationary. If 'open' left most point allowed to \n        diffuse Defaults to 'closed'.\n\n    Raises:\n        Exception: if numerically unstable an error will be thrown\n\n    Returns:\n        curves (array-like): a (timegrid,x) shape array of diffusion curves\n        where each row in the array represents a diffusion curve at a discrete\n        timestep. \n    \"\"\"\n\n    ni = x.shape[0]\n    nj = timegrid.shape[0]\n\n    curves = np.empty((nj, ni))\n    curves[0, :] = init_prof.copy()  # initial profile\n\n    dt = timegrid[1] - timegrid[0]\n    dx = x[1] - x[0]  # assume all x points are evenly spaced\n\n    r = (diff_coef * dt) / dx**2  # constant\n\n    if r &gt;= 0.5:\n        raise Exception(\n            \"You do not have numerical stability, please adjust your \\\n            timegrid accordingly. Remember D * dt / dx**2 must be &lt; 0.5\"\n        )\n\n    else:\n\n        for j in range(0, nj - 1):\n            curves[j + 1, 1 : ni - 1] = curves[j, 1 : ni - 1] + r * (\n                curves[j, 0 : ni - 2] - 2 * curves[j, 1 : ni - 1] + curves[j, 2:ni]\n            )\n            if left_side == \"closed\":\n\n                curves[j + 1, 0] = init_prof[0]  # fix left point\n            elif left_side == \"open\":\n\n                curves[j + 1, 0] = curves[j, 0] + r * (\n                    curves[j, 1] - 2 * curves[j, 0] + curves[j, 1]\n                )  # let left point diffuse\n\n            else:\n                raise Exception(\n                    \"Please choose either 'open' or 'closed' for the \\\n                    left side boundary condition\"\n                )\n\n            curves[j + 1, -1] = init_prof[-1]  # fix right point\n\n    return curves\n\n\nApply the function:\n\n\nShow the code\nmodel_curves = FickFD_constant(\n    x=px_data[\"x\"],\n    timegrid=timegrid,\n    diff_coef=Dc,\n    init_prof=initial_profile,\n    left_side=\"closed\",\n)\n\n\nVisualize the results:\n\n\nShow the code\nplot_iterations = [\n    10,\n    100,\n    1000,\n    10000,\n]\nfig, ax = plt.subplots(figsize = (4,4))\nax.plot(px_data[\"x\"], initial_profile, c=\"k\", label=\"initial\")\nfor iteration in plot_iterations:\n\n    ax.plot(px_data[\"x\"], model_curves[iteration, :], label=f\"iteration {iteration}\")\nax.legend(loc=\"upper right\")\nax.set_xlabel(r\"Distance ($\\mu$m)\")\nax.set_ylabel(\"Concentration\")\nplt.show()\n\n\n\n\n\n\n\n\n\nFinding the best fit to the observed data can be done by comparing each model curve to the observed data, finding an overall misfit between the two curves, and looking for the minimum misfit. There are a couple metrics to do this by and they’ll all probably converge on the same answer, but we’ll use the \\(\\chi ^2\\), which can be defined as:\n\\[\n\\chi^2_j = \\sum_{i=1}^{n_i} \\frac{(O_{i,j} - E_{i,j})^2}{E_{i,j}}\n\\]\nwhere \\(O_i\\) is a given spot, \\(i\\) in the diffusion model at time \\(j\\), and \\(E_i\\) is the measured data at that point in the distance grid.\nDefine the function:\n\n\nShow the code\n# fitting the model using chi squared\ndef fit_model(te, curves, metric=\"chi\"):\n    \"\"\"\n    Find the best fit timestep for the diffusion model that matches the\n    observed data. Uses a standard chi-squared goodness of fit test.\n\n    Parameters\n    ----------\n    te : ndarray\n        the observed (measured) trace element profile in the plagioclase\n    curves : ndarray\n        array that is t.shape[0] x distance.shape[0] and pertains to a \n        diffusion curve for each timestep in the model.\n\n    Returns\n    -------\n    bf_time : int\n       the best fit iteration of the model. Can be plotted as follows:\n\n           fig,ax = plt.subplots()\n           ax.plot(dist,curves[bf_time,:])\n\n    \"\"\"\n    if type(te) == pd.Series:\n        te = np.array(te)\n\n    if metric == \"chi\":\n\n        # sum chi2 value for all curves\n        chi2 = abs(np.sum((curves - te[None, :]) ** 2 / (te[None, :]), axis=1))\n\n        # find the minimum value\n        chi2_min = np.min(chi2)\n\n        # find where in the array it is (e.g., it's position)\n        fit_idx = np.argwhere(chi2 == chi2_min)\n\n        # Get that array index\n        fit_idx = fit_idx[0].item()\n\n        # add one because python starts counting at 0\n        bf_time = fit_idx + 1\n\n        return bf_time, chi2\n    elif metric == \"rmse\":\n        rmse = np.sqrt(np.sum((curves - te[None, :]) ** 2, axis=1) / curves.shape[1])\n\n        rmse_min = np.min(rmse)\n\n        fit_idx = np.argwhere(rmse == rmse_min)\n\n        # Get that array index\n        fit_idx = fit_idx[0].item()\n\n        # add one because python starts counting at 0\n        bf_time = fit_idx + 1\n\n        return bf_time, rmse\n\n\nApply the function:\n\n\nShow the code\nbest_fit_rmse, rmse_values = fit_model(px_data[\"Mg_num\"], model_curves, metric=\"rmse\")\nbest_fit_chi2, chi2_values = fit_model(px_data[\"Mg_num\"], model_curves, metric=\"chi\")\n\nexcel_best_fit = 1602\npx_data[f\"best_fit_model\"] = model_curves[best_fit_rmse, :]\n\nfig, ax = plt.subplots(figsize = (4,4))\n\ndt = timegrid[1] - timegrid[0]\n\nsec_to_day = 60 * 60 * 24\n\nax.plot(timegrid / sec_to_day, chi2_values, lw=2, label=r\"$\\chi ^2$\")\nax.plot(timegrid / sec_to_day, rmse_values, lw=2, label=\"RMSE\")\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\n    \"time (days)\",\n)\nax.set_ylabel(\n    \"misfit\",\n)\nax.legend(loc=\"lower left\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nVisualize the overall model results:\n\n\nShow the code\nbf_color = \"C1\"\nexcel_color = \"C8\"\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\nax[0].plot(\"x\", \"initial_profile\", data=px_data, c=\"k\", label=\"initial\")\nax[0].plot(\"x\", \"Mg_num\", data=px_data, label=\"observed\")\nax[0].plot(\n    \"x\",\n    \"best_fit_model\",\n    data=px_data,\n    label=f\"best fit: {best_fit_rmse} days\",\n    c=bf_color,\n)\nax[0].plot(\n    px_data[\"x\"],\n    model_curves[excel_best_fit, :],\n    c=excel_color,\n    ls=\"--\",\n    label=f\"Excel fit: {excel_best_fit} days\",\n)\nax[0].legend(loc=\"upper right\")\nax[0].set_xlabel(r\"Distance ($\\mu$m)\")\nax[0].set_ylabel(\"Concentration\")\n\ndt = timegrid[1] - timegrid[0]\n\nsec_to_day = 60 * 60 * 24\n\nax[1].plot(\n    timegrid / sec_to_day,\n    chi2_values,\n    \"-k\",\n    lw=2,\n)\n\n# vertical line at best fit value\nax[1].axvline(\n    best_fit_chi2,\n    color=bf_color,\n    label=fr\"best fit: {best_fit_rmse} days @ {int(T_K - 273.15)}$^{{\\circ}}$C\",\n),\nax[1].axvline(\n    excel_best_fit,\n    color=excel_color,\n    ls=\"--\",\n    label=fr\"best fit excel: {excel_best_fit} days @ {int(T_K - 273.15)}$^{{\\circ}}$C\",\n),\nax[1].set_xlabel(\n    \"time (days)\",\n)\nax[1].set_ylabel(\n    r\"$\\sum{\\chi^2} $\",\n)\nax[1].set_xscale(\"log\")\nax[1].legend(\n    loc=\"best\",\n)\nax[1].set_yscale(\"log\")\n\nfig.suptitle(\"1947-2_pyr27_BSE-1\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nUncertainties\nQuantifying uncertainties in any model is a critical task that helps with their accurate interpretation and diffusion models are no different. The main source of uncertainty in diffusion models are those induced by uncertainties in model temperature and parameters that go into calculating the diffusion coefficient. There are a couple ways to go about this:\n\nclassical error propagation\nmonte carlo estimation\n\nThere is also the uncertainty associated with the observed data, itself, but we’ll deal with those later.\nWe’ll start with a classical error propagation approach. Suppose variables x, y, z are measured with uncertainties \\(\\sigma _x\\), \\(\\sigma_y\\), and \\(\\sigma _z\\), and used to compute the function \\(q(x,y,z)\\). If uncertainties are independent and random, the uncertainty in \\(q\\) is (Taylor 2022):\n\\[\n\\sigma _q = \\sqrt{{(\\frac{\\delta q}{\\delta x}\\sigma_x)}^2 + {(\\frac{\\delta q}{\\delta y}\\sigma_y)}^2 + {(\\frac{\\delta q}{\\delta z}\\sigma_z)}^2 }\n\\]\nApplied to the Arrhenius relationship used to calculate diffusion coefficients:\n\\[\nD = D_0\\exp(\\frac{-E}{RT})\n\\]\nThe uncertainty in our diffusion coefficient is then:\n\\[\n\\sigma _D = \\sqrt{{(\\frac{\\delta D}{\\delta D_0}\\sigma _{D_0})}^2 + {(\\frac{\\delta D}{\\delta E}\\sigma _E)}^2 + {(\\frac{\\delta D}{\\delta T}\\sigma _T)}^2 }\n\\]\nSkipping some algebra and taking each derivative ultimately yields:\n\\[\n\\sigma _D = \\sqrt{{(\\exp[\\frac{-E}{RT}]\\sigma _{D_0})}^2 + {(\\frac{-D_0\\exp[\\frac{-E}{RT}]}{RT}\\sigma _E)}^2 + {(\\frac{D_0\\exp[\\frac{-E}{RT}]E}{RT^2}\\sigma _T)}^2 }\n\\]\nWith Fe-Mg diffusion rates in orthopyroxene, the uncertainty in D0 itself is basically due to the uncertainty \\(f_{O_2}\\) measurements:\n\\[\nD_0 = (10^{X_{Fe}-0.09}) 1.12\\times 10^{-6}{f_{O_2}}^{0.053\\pm 0.027}\n\\]\nFollowing the above general error propagation logic, the uncertainty in this term can then be written as:\n\\[\n\\sigma f_{0_2} = \\frac{\\delta f_{0_2}}{\\delta x}\\sigma _x\n\\]\nTaking this derivative, and adding in the constants for the D0 term, our uncertainty in the D0 is then:\n\\[\n\\sigma _{D_0} = 1.12\\times 10^{-6}\\times 10^{X_{Fe} - 0.09}\\ln (f_{O_2}){f_{O_2}}^{0.053} 0.027\n\\]\n\n\nShow the code\nsigma_D0 = 1.12e-6 * 10 ** (X_Fe - 0.09) * (fo2**0.053 * np.log(fo2) * 0.027)\nsigma_Ea = 23e3\nsigma_T = 30\nR = 8.314\n\nd_term = (np.exp(-Ea / (R * T_K)) * sigma_D0) ** 2\ne_term = (-D0 * np.exp(-Ea / (R * T_K)) * sigma_Ea / (R * T_K)) ** 2\nT_term = (D0 * np.exp(-Ea / (R * T_K)) * Ea * sigma_T / (R * T_K**2)) ** 2\n\nsigma_Dc = np.sqrt(d_term + e_term + T_term)\nprint(f\"D: {Dc/1e12}\\nstd dev: {sigma_Dc}\")\n\n\nD: 5.495802398029777e-20\nstd dev: 1.3328011987124054e-19\n\n\nThat was kind of a pain. And a lot of calculus. Fortunately, there is a standard libary included in scipy installs: uncertainties. This will allow us to easily propagate our errors and display them. To accomplish the above calculus and computation we can simply redefine some of our variables to include their uncertainties:\n\n\nShow the code\nfo2_exp = ufloat(0.053, 0.027)\nfo2_term = fo2**fo2_exp\n\nD0 = 1.12e-6 * fo2_term * 10 ** (X_Fe - 0.09)\nEa = ufloat(308e3, 23e3)\nT_K = ufloat(970 + 273.15, 30)\n\nD_new = D0 * unumpy.exp(-Ea / (8.314 * T_K))\nunc_factor = D_new.std_dev / D_new.nominal_value\nprint(\n    f\"D: {D_new.nominal_value}\\nstd dev: {D_new.std_dev}\\nrelative std \\\n    dev: {int(100 * unc_factor)}%\"\n)\n\n\nD: 5.495802398029777e-20\nstd dev: 1.3328011987124056e-19\nrelative std     dev: 242%\n\n\nNow for the fine print. Our classical approach to error propagation is largely based on linear approximations. What does this mean? From the uncertainties package documentation:\n\nThe standard deviations and nominal values calculated by this package are thus meaningful approximations as long as uncertainties are “small”. A more precise version of this constraint is that the final calculated functions must have precise linear expansions in the region where the probability distribution of their variables is the largest. Mathematically, this means that the linear terms of the final calculated functions around the nominal values of their variables should be much larger than the remaining higher-order terms over the region of significant probability (because such higher-order contributions are neglected).   For example, calculating x*10 with x = 5±3 gives a perfect result since the calculated function is linear. So does umath.atan(umath.tan(x)) for x = 0±1, since only the final function counts (not an intermediate function like tan()).   Another example is sin(0+/-0.01), for which uncertainties yields a meaningful standard deviation since the sine is quite linear over 0±0.01. However, cos(0+/-0.01), yields an approximate standard deviation of 0 because it is parabolic around 0 instead of linear; this might not be precise enough for all applications.\n\nA way around this would be to implement a Monte Carlo approach. In brief, this will compute the diffusion coefficient many times, but each time the values that contain uncertainties are randomly selected from their probability distribution (mean, standard deviation). This looks something like the following:\n\n\nShow the code\nn_iterations = 10000\nD_mc = diffusivity(\n    1.12e-6\n    * fo2 ** np.random.normal(fo2_exp.nominal_value, fo2_exp.std_dev, n_iterations)\n    * 10 ** (X_Fe - 0.09),\n    np.random.normal(Ea.nominal_value, Ea.std_dev, n_iterations),\n    np.random.normal(T_K.nominal_value, T_K.std_dev),\n)\nlnD_mc = np.log(D_mc)\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\n\nax[0].hist(D_mc, bins=50)\nax[0].set_yscale(\"log\")\nax[0].set_xlabel(\"D\")\nax[1].hist(lnD_mc, bins=50)\nax[1].set_xlabel(r\"$\\ln{(D)}$\")\nfor a in ax:\n    mpl_defaults.left_bottom_axes(a)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nIn looking at the distribution of D values generated from the Monet Carlo simulation, we see that the distribution is highly log-normal. While we can take the standard deviation of this distribution, the reality that \\({\\sim}\\) 68% of values are within 1 standard deviation of the mean only applies to normal distributions. We should therefore try to make our distribution of D values as normal as possible. In this case we can take the natural log of D values (a clue here is that Arrhenius relationships have \\(\\exp\\) in the function) to transform them to resemble a normal distribution. Once we have a normal distribution, we can take the mean and standard deviation. It is important to note, however, that these values are in the transformed units!! So what we must then do is back transform those values into “real” values…in this case \\(\\ln(\\frac{\\mu m^2}{s}) \\rightarrow (\\frac{\\mu m^2}{s})\\). We do this by appling the np.exp function.\n\n\nShow the code\nlnD_mc_mean = np.mean(lnD_mc)\nlnD_mc_std = np.std(lnD_mc)\n\n# back transform into normal units\nD_mc_mean = np.exp(lnD_mc_mean)\nD_mc_lower_bound = np.exp(lnD_mc_mean - lnD_mc_std)\nD_mc_upper_bound = np.exp(lnD_mc_mean + lnD_mc_std)\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\n\nax[0].hist(D_mc, bins=50)\nax[0].axvline(D_mc_mean, c=\"C1\")\nax[0].axvline(D_mc_lower_bound, c=\"C1\", ls=\"--\")\nax[0].axvline(D_mc_upper_bound, c=\"C1\", ls=\"--\")\nax[0].set_yscale(\"log\")\n\n\naxins = ax[0].inset_axes(\n    [0.2, 0.6, 0.3, 0.3],\n    xlim=(-1e-19,1.3*D_mc_upper_bound), ylim=ax[0].get_ylim(),\n\n)\n\n\naxins.hist(D_mc,bins = 50,zorder = 0)\naxins.axvline(D_mc_mean, c=\"C1\")\naxins.axvline(D_mc_lower_bound, c=\"C1\", ls=\"--\")\naxins.axvline(D_mc_upper_bound, c=\"C1\", ls=\"--\")\naxins.set_yscale(\"log\")\nax[0].indicate_inset_zoom(axins, edgecolor=\"black\",zorder = 1)\naxins.set_yticks([])\naxins.set_xticks([D_mc_lower_bound,D_mc_mean,D_mc_upper_bound])\n\naxins.set_xticklabels([f\"{val:.2E}\" for val in [D_mc_lower_bound,D_mc_mean,D_mc_upper_bound]],rotation = 90,fontsize = 4)\nfor spine in ['top','bottom','left','right']:\n    axins.spines[spine].set_linewidth(1)\n\nmpl_defaults.left_bottom_axes(axins)\n\nax[0].set_xlabel(\"D\")\n\nax[1].hist(lnD_mc, bins=50)\nax[1].axvline(lnD_mc_mean, c=\"C1\")\nax[1].axvline(lnD_mc_mean + lnD_mc_std, c=\"C1\", ls=\"--\")\nax[1].axvline(lnD_mc_mean - lnD_mc_std, c=\"C1\", ls=\"--\")\nax[1].set_xlabel(r\"$\\ln{(D)}$\")\nfor a in ax:\n    mpl_defaults.left_bottom_axes(a)\n\n\nax[0].set_title('Back transformed uncertainties on D',fontsize = 12)\nax[1].set_title(r'$\\mu \\pm \\sigma$ for $\\ln{(D)}$',loc = 'center',fontsize = 12)\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\nOur uncertainties in “regular” units are asymmetric! This is where classical linear error propagation theory has led us astray. Rather than thinking about our timescales in standard deviations, then, it might be more useful to think about this in confidence limits. We can find lower and upper timescale confidence limits relative to the mean best fit time and then apply it to our model:\n\n\nShow the code\n# difference of upper bound relative to mean\nupper_conf_limit = abs(D_mc_upper_bound - D_mc_mean) / (D_mc_mean)\n# difference of lower bound relative to mean\nlower_conf_limit = abs(D_mc_lower_bound - D_mc_mean) / D_mc_mean\n\n\nprint(f\"Your model best fit is {best_fit_rmse:.2E} days\")\nprint(f\"The lower confidence limit is {best_fit_rmse*lower_conf_limit:.2} days\")\nprint(f\"The upper confidence limit is {best_fit_rmse*upper_conf_limit:.2} days\")\n\n\nYour model best fit is 1.60E+03 days\nThe lower confidence limit is 1.4e+03 days\nThe upper confidence limit is 1.4e+04 days\n\n\nHere, we have 68% confidence that the calculated \\(D\\) value is between the upper and lower limits. This is commonly referred to as a confidence interval. A 95% confidence interval would be created by going 2 standard deviations away from the mean in \\(ln(D)\\) space rather than 1 like shown above:\nlnD_mc_std = np.std(lnD_mc) # 68 % confidence \nlnD_mc_2std = 2*np.std(lnD_mc) # 95% confidence \n\n\nFe-Mg in olivine\nFe-Mg interdiffusion rates (\\(\\frac{m^2}{s}\\)) in olivine along the c-axis can be explained by the following relationship (Chakraborty 2010). At \\(f_{O_2}\\) &gt; \\(10^{-10}\\) Pa:\n\\[\nD = 10^{-9.21}\\left[\\frac{f_{O_2}}{10^{-7}}\\right]^{\\frac{1}{6}}10^{3(X_{Fe} - 0.1)}\\exp{\\left(\\frac{-201000 + (P-10^{-5})7\\times 10^{-6}}{RT}\\right)}\n\\]\nWhere T is in Kelvin, P and \\(f_{O_2}\\) are in Pascals, XFe is the mole fraction of the fayalite component, and R is the gas constant in J/mol\\(\\cdot\\)K (8.314). Diffusion rates along the a and b axes are 6 times slower than along c. This example lends itself nicely to our tutorial because it introduces an implementation of the solution to the diffusion equation where the diffusion coefficient is dependendent on the composition of the mineral (see above for refresher). Having gone through much of the workflow in the pyroxene demo we are ready to load in some data. This is from Lynn et al., (in press Bulletin of Volcanology).\n\n\nShow the code\n# this is how you load in MATLAB matrices\nfrom scipy.io import loadmat\n\n# Fo profile\nol_Fo = loadmat(r\".\\data\\Fo_epma.mat\")\nol_Fo = ol_Fo[\"Fo_epma\"].flatten() / 100\n\n# uncertainty on Fo\nol_err = loadmat(r\".\\data\\err.mat\")\nol_err = ol_err[\"err\"].flatten() / 100\n\n# CaO data\nol_cao = loadmat(r\".\\data\\CaO.mat\")\nol_cao = ol_cao[\"CaO\"].flatten()\n\n# initial profile\nol_Fo_init = loadmat(r\".\\data\\Fo_init.mat\")\nol_Fo_init = ol_Fo_init[\"Fo_init\"].flatten() / 100\n\n# distance profile\nol_dist = loadmat(r\".\\data\\x.mat\")\nol_dist = np.flip(ol_dist[\"x\"].flatten())\n\n# combine them all into one DataFrame\nol_data = pd.DataFrame(\n    {\"Fo\": ol_Fo, \"Fo_err\": ol_err, \"CaO\": ol_cao,\n        \"Fo_init\": ol_Fo_init, \"x\": ol_dist}\n)\nol_data.head()\n\n\n\n\n\n\n\n\n\n\nFo\nFo_err\nCaO\nFo_init\nx\n\n\n\n\n0\n0.881510\n0.001\n0.2382\n0.882\n0.0000\n\n\n1\n0.881638\n0.001\n0.2242\n0.882\n11.8424\n\n\n2\n0.882790\n0.001\n0.2269\n0.882\n23.9281\n\n\n3\n0.881857\n0.001\n0.2342\n0.882\n36.0695\n\n\n4\n0.879441\n0.001\n0.2200\n0.882\n48.0509\n\n\n\n\n\n\n\n\nPlot it up!\n\n\nShow the code\nfig, ax = plt.subplots(2, 1, figsize=(4, 8))\n\nax[0].errorbar(\n    x=\"x\",\n    y=\"Fo\",\n    yerr=\"Fo_err\",\n    data=ol_data,\n    marker=\"o\",\n    ms=4,\n    ls=\"\",\n    mfc=\"white\",\n    mec=\"C0\",\n    label=\"observed\",\n)\n\nax[0].plot(\"x\", \"Fo_init\", data=ol_data, c=\"black\", label=\"initial\")\nax[0].legend(loc=\"lower left\")\nax[0].set_ylabel(\"X$_{Fo}$\")\n\nax[1].plot(\n    \"x\",\n    \"CaO\",\n    data=ol_data,\n    marker=\"o\",\n    ls=\"\",\n    ms=4,\n    mfc=\"white\",\n    mec=\"C1\",\n    label=\"observed\",\n)\nax[1].legend(loc=\"upper left\")\nax[1].set_ylabel(\"CaO (wt%)\")\nax[1].set_xlabel(r\"Distance ($\\mu$m)\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCalculate the diffusion coefficient:\nDefine the function:\n\n\nShow the code\ndef olivine_diffusivity(X_Fo, pressure, fo2, temperature, species=\"fe-mg\"):\n    \"\"\"_summary_\n\n    Args:\n        X_Fo (array-like): mol fraction forsterite\n        pressure (scalar): pressure of crystallization in pascals\n        fo2 (scalar): oxygen fugacity of crystallization in pascals\n        temperature (scalar): temperature of crystallization in pascals\n        species (str, optional): diffusing species. Currently only supports \n        \"fe-mg\". Defaults to \"fe-mg\".\n\n    Returns:\n        Dc, Da, Db : Diffusion coefficent for each crystallographic axis. \n        To find the diffusion coefficient across a given traverse. \n        If alpha, beta, gamma are the angle of the traverse to the a, b, \n        and c axis respectively:\n\n        \n        D_traverse = Da*np.cos(np.deg2rad(alpha))**2+ \\\n            Db*np.cos(np.deg2rad(beta))**2+ Dc*np.cos(np.deg2rad(gamma))**2\n\n\n    \"\"\"\n    X_Fe = np.array(1 - X_Fo)\n    if species == \"fe-mg\":\n\n        Dc = (\n            10**-9.21\n            * (fo2 / 1e-7) ** (1 / 6)\n            * 10 ** (3 * (X_Fe - 0.1))\n            * np.exp(-(201e3 + (pressure - 1e5) * 7e-6) / (8.314 * temperature))\n            * 1e12\n        )\n        Da = Dc / 6\n        Db = Dc / 6\n\n    return Dc, Da, Db\n\n\nApply the function:\n\n\nShow the code\n# parameters for diffusion coefficient\nT_K = 1200 + 273.15  # Temperature in K\nfo2 = (10**-8.2) * 10**5  # oxygen fugacity in Pa\nP = 42000000  # pressure in Pa\n\n# crystallographic orientation\nalpha = 17  # in degrees, a axis to traverse angle\nbeta = 73  # in degrees, b axis to traverse angle\ngamma = 91  # in degrees, c axis to traverse angle\n\n\n\nDc, Da, Db = olivine_diffusivity(\n    X_Fo=ol_data[\"Fo\"].values, pressure=P, fo2=fo2, temperature=T_K\n)\nD_traverse = (\n    Da * np.cos(np.deg2rad(alpha)) ** 2\n    + Db * np.cos(np.deg2rad(beta)) ** 2\n    + Dc * np.cos(np.deg2rad(gamma)) ** 2\n)\n\n\nApply the compositionally dependent D value solution to our timegrid:\nDefine the function:\n\n\nShow the code\ndef FickFD_comp_dependent(\n    x,\n    timegrid,\n    init_prof,\n    pressure,\n    fo2,\n    temperature,\n    alpha,\n    beta,\n    gamma,\n    left_side=\"closed\",\n    right_side=\"closed\",\n):\n    \"\"\"\n    Forward model diffusion for olivine according to Fick's 2nd Law with a\n    diffusion coefficient that is dependent on composition. Because the diffusion\n    coefficient needs to be calculated at each iteration, this will calculate the \n    diffusion coefficient for you based off the fo2, temperature, and transect \n    orientation relative to the a, b, and c axes. \n\n\n    Args:\n        x (array-like): distance profile\n        timegrid (array-like): array of time values to iterate through. Output\n        of get_timegrid()\n        init_prof (array-like): profile representing model starting condition\n        pressure (scalar): _description_\n        fo2 (scalar): oxygen fugacity in pascals\n        temperature (scalar): temperature in Kelvin\n        alpha (scalar): angle to a-axis in degrees\n        beta (scalar): angle to b-axis in degrees\n        gamma (scalar): angle to c-axis in degrees\n        left_side (str, optional): left side boundary condition. If 'closed'\n        then the left side is stationary. If 'open' left most point allowed to \n        diffuse Defaults to 'closed'.\n        right_side (str, optional): right side boundary condition. If 'closed'\n        then the right side is stationary. If 'open' right most point allowed to \n        diffuse Defaults to 'closed'.\n\n    Raises:\n        Exception: error for not being numerically stable\n        Exception: error for not specifying boundary conditions correctly\n\n    Returns:\n        curves (array-like): a (timegrid,x) shape array of diffusion curves\n        where each row in the array represents a diffusion curve at a discrete\n        timestep. \n    \"\"\"\n\n    ni = x.shape[0]\n    nj = timegrid.shape[0]\n    if np.any(init_prof &gt; 1):\n        init_prof = init_prof / 100\n\n    curves = np.empty((nj, ni))\n    curves[0, :] = init_prof.copy()  # initial profile\n\n    dt = timegrid[1] - timegrid[0]\n    dx = x[1] - x[0]  # assume all x points are evenly spaced\n\n    Dc, Da, Db = olivine_diffusivity(\n        X_Fo=init_prof, pressure=pressure, fo2=fo2, temperature=temperature\n    )\n\n    r = (Dc * dt) / dx**2  # constant\n\n    if np.any(r &gt;= 0.5):\n        raise Exception(\n            \"You do not have numerical stability, please adjust your timegrid \\\n            accordingly. Remember D * dt / dx**2 must be &lt; 0.5\"\n        )\n\n    else:\n\n        for j in range(0, nj - 1):\n\n            Dc, Da, Db = olivine_diffusivity(\n                X_Fo=curves[j, :], pressure=pressure, fo2=fo2, temperature=temperature\n            )\n            D = (\n                Da * np.cos(np.deg2rad(alpha)) ** 2\n                + Db * np.cos(np.deg2rad(beta)) ** 2\n                + Dc * np.cos(np.deg2rad(gamma)) ** 2\n            )\n\n            # D = diff_coef*10**(3*(0.9-curves[j,:])) #adjust D for composition\n\n            curves[j + 1, 1 : ni - 1] = (\n                curves[j, 1 : ni - 1]\n                + dt\n                / dx**2\n                * ((D[2:ni] - D[1 : ni - 1]))\n                * ((curves[j, 2:ni] - curves[j, 1 : ni - 1]))\n                + D[1 : ni - 1]\n                * dt\n                * (\n                    (curves[j, 2:ni] - 2 * curves[j, 1 : ni - 1] + curves[j, : ni - 2])\n                    / dx**2\n                )\n            )\n\n            if left_side == \"closed\":\n\n                curves[j + 1, 0] = init_prof[0]  # fix left point\n\n            elif left_side == \"open\":\n                curves[j + 1, 0] = (\n                    curves[j, 0]\n                    + dt / dx**2 * ((D[1] - D[0])) * ((curves[j, 1] - curves[j, 0]))\n                    + D[0]\n                    * dt\n                    * ((curves[j, 1] - 2 * curves[j, 0] + curves[j, 1]) / dx**2)\n                )\n\n            if right_side == \"closed\":\n\n                curves[j + 1, -1] = init_prof[-1]  # fix left point\n\n            elif right_side == \"open\":\n\n                curves[j + 1, -1] = (\n                    curves[j, -1]\n                    + dt / dx**2 * ((D[-2] - D[-1])) * ((curves[j, -2] - curves[j, -1]))\n                    + D[-1]\n                    * dt\n                    * ((curves[j, -2] - 2 * curves[j, -1] + curves[j, -2]) / dx**2)\n                )\n\n            else:\n                raise Exception(\n                    \"Please choose either 'open' or 'closed' for the left \\\n                    side boundary condition\"\n                )\n\n    return curves\n\n\nApply the function:\n\n\nShow the code\n# time grid\ntgrid = get_tgrid(1e4, \"hours\")\n\n\n# compositional dependent D solution\nchanging_model_curves = FickFD_comp_dependent(\n    x=ol_data[\"x\"].values,\n    timegrid=tgrid,\n    init_prof=ol_data[\"Fo_init\"].values,\n    pressure=P,\n    fo2=fo2,\n    temperature=T_K,\n    alpha=alpha,\n    beta=beta,\n    gamma=gamma,\n    left_side=\"closed\",\n    right_side=\"closed\",\n)\n\n\nFind the best fit iteration:\n\n\nShow the code\nbest_fit_rmse, rmse_values = fit_model(\n    ol_data[\"Fo\"], changing_model_curves, metric=\"rmse\"\n)\n\n\nVisualize the results:\n\n\nShow the code\nhours2yrs = 24 * 365.25\nhours2days = 24\nsinday = 60*60*24\nsinyr = hours2yrs * 60 * 60\nfig, ax = plt.subplots(1, 2, figsize=(8, 4), layout=\"constrained\")\n\n\nax[0].errorbar(\n    x=\"x\",\n    y=\"Fo\",\n    yerr=\"Fo_err\",\n    data=ol_data,\n    marker=\"o\",\n    ms=4,\n    ls=\"\",\n    mfc=\"white\",\n    mec=\"C0\",\n    label=\"observed\",\n)\n\n\nax[0].plot(\n    ol_data[\"x\"],\n    changing_model_curves[best_fit_rmse, :],\n    label=f\"best fit: {np.round(best_fit_rmse/hours2days,2)} days\",\n)\n\nax[0].plot(\"x\", \"Fo_init\", data=ol_data, c=\"black\", label='initial')\n\n\nax[0].legend(loc=\"lower left\")\n\nax[0].set_ylabel(\"X$_{Fo}$\", fontsize=20)\nax[0].set_xlabel(r\"Distance ($\\mu$m)\", fontsize=20)\n\n\nax[1].plot(tgrid / sinday, rmse_values, \"k-\")\nax[1].axvline(\n    tgrid[best_fit_rmse] / sinday,\n    c=\"C1\",\n    lw=2,\n    label=f\"best fit: {np.round(best_fit_rmse/hours2days,2)} days\",\n)\nax[1].legend(loc=\"lower right\")\nax[1].set_xlabel(\"model time (days)\", fontsize=20)\nax[1].set_ylabel(\"RMSE\", fontsize=20)\n\nax[0].set_title(\n    fr\"T: {int(T_K - 273.15)} $^{{\\circ}}$C \", loc=\"left\", fontstyle=\"italic\"\n)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSr in plagioclase\nSr and Mg flux in plagioclase is a result of two things:\n\ndiffusion in response to its own gradient\ndiffusion in response to gradients in \\(X_{An}\\).\n\nThis warrants a special solution to the diffusion equation. A detailed explanation of this can be found in F. Costa, Chakraborty, and Dohmen (2003) and is expanded on by Dohmen, Faak, and Blundy (2017) and the Appendix of Lubbers, Kent, and Silva (2024). A synopsis:\n\nRemember Fick’s 1st Law:\n\n\\[\nJ = -D\\frac{\\delta C}{\\delta x}\n\\]\n\nAnd Fick’s 2nd Law:\n\n\\[\n\\frac{\\delta C}{\\delta t} = D\\frac{\\delta ^2C}{\\delta x^2}\n\\]\n\nCombining these we get:\n\n\\[\n\\frac{\\delta C}{\\delta t} = \\frac{\\delta }{\\delta x}(-J)\n\\]\n\nSince for plagioclase:\n\n\\[\nJ = -D_{Sr}\\frac{\\delta C_{Sr}}{\\delta x} + \\frac{D_{Sr}C_{Sr}}{RT}A_{Sr}\\frac{\\delta X_{An}}{\\delta x}\n\\] The final solution to describe how trace elements diffuse in plagioclase with time is:\n\\[\n\\frac{\\delta C}{\\delta t} = \\frac{\\delta}{\\delta x}\\left[ D_{Sr}\\frac{\\delta C_{Sr}}{\\delta x} - \\frac{D_{Sr}C_{Sr}}{RT}A_{Sr}\\frac{\\delta X_{An}}{\\delta x}\\right]\n\\]\nTo help ensure a more stable solution, Dohmen, Faak, and Blundy (2017) employ another half-space in the \\(x\\) direction:\n\\[\nD(x_{i+0.5}) \\frac{\\delta C}{\\delta x}(x_{i+0.5}) \\approx D_{i+0.5}\\frac{C_{i+1}-C_i}{\\Delta x}\n\\]\nApplying this to the above solution we can then describe how the concentration of Sr in plagioclase evolves with respect to space (\\(i\\)) and time (\\(j\\)):\n\n\n\n\n\n\nFinal Solution\n\n\n\n\\[\\tiny{\nC_{i,j+1} = \\frac{\\Delta t}{\\Delta x^2}\\left[C_{i+1,j}\\left( D_{i+0.5,j} -  \\frac{D_{i+0.5,j}\\Theta}{2}(An_{i+1} - An_i) \\right) - C_{i,j}\\left(D_{i+0.5,j} + D_{i-0.5,j} +  \\frac{D_{i+0.5,j}\\Theta}{2}(An_{i+1} - An_i) -  \\frac{D_{i-0.5,j}\\Theta}{2}(An_{i} - An_{i-1}) \\right)  +C_{i-1,j}\\left( D_{i-0.5,j} -  \\frac{D_{i-0.5,j}\\Theta}{2}(An_{i} - An_{i-1}) \\right)  \\right]}\n\\]\n\n\nwhere: \\[\n\\Theta = \\frac{A}{RT}\n\\]\nHere \\(A\\) comes from the relationship that describes how the activity coefficient (\\(\\gamma\\)) changes with \\(X_{An}\\) from Dohmen and Blundy (2014): \\[\\\n-RTln({\\gamma}) = AX_{An} + B\n\\]\nCritically, because Sr diffuses significantly faster than the chemical exchange of anorthite and albite, it will equilibrate sufficiently fast such that the An profile can considered stationary. Because the flux of Sr in plagioclase, as shown above, is controlled in part by the An content, the quasi-equilibrium state (i.e., equilibrium state for a given An content) will be heterogeneous. For Sr, that has an activity coefficient that increases with An content, the quasi-equilibrium state will be inversely correlated with An content Dohmen, Faak, and Blundy (2017).\nAs crystals are open to chemical exchange with the surrounding melt [e.g., infinite reservoir assumption; Crank (1979)], the chemical potential of Sr is fixed at the rim. With the understanding that it is not actually the concentration gradient that drives diffusion, but the chemical potential gradient, when the chemical potential at any point in our transect matches that of the rim, we can say we have reached a quasi-equilibrium situation for that An distribution. Formally this can be thought of as \\(\\frac{\\delta C}{\\delta t} = 0\\) and \\(J_i(x) = J_s = 0\\). With respect to our Sr profile, this is explained by: \\[\n{C_{Sr}^{eq}}(x) = {C_{Sr}^{0}}\\exp{\\left[\\frac{A_{Sr}}{RT}X_{An}(x)\\right]}\n\\]\n\nWhere\n\n\\[\n{C_{Sr}^{0}} = {C_{Sr}^{rim}}\\exp{\\left[\\frac{-A_{Sr}}{RT}{X_{An}^{rim}}\\right]}\n\\]\nBelow we’ll walk through how to implement the above maths. It relies heavily on the small module plag_diff. I strongly consider looking this over and getting familiar with it! It requires two additional packages:\n\nmendeleev: For working with elemental data (e.g., atmomic masses, atomic numbers)\nstatsmodels: implementation of statistical models in python. In our case regressions.\ntqdm: displaying progress bars in python\n\n\n\nShow the code\nimport plag_diff as plag\nfrom tqdm.notebook import tqdm\n\n\nJust like any function in python, plag_diff functions can be utilized with the help() function to find out more information:\n\n\nShow the code\nhelp(plag.dohmen_kd_calc)\n\n\nHelp on function dohmen_kd_calc in module plag_diff:\n\ndohmen_kd_calc(element, An, sio2_melt, temp)\n    calculate the partition coefficient of either Sr, Mg, or Ba\n            in plagioclase according to the thermodynamic model outlined in\n            Dohmen and Blundy (2014) doi: 10.2475/09.2014.04\n    \n            where partition coefficients for Ca and Na are derived from\n            using the LEPR database (Eqs 28a-b).\n    \n            Will also calculate A and B parameters required for modeling\n            diffusion of Sr and Mg as outlined in Costa et al. (2003)\n            doi: 10.1016/S0016-7037(02)01345-5 which is effectively\n            a regression of RTln(Kd) vs X_An where A is the slope\n            and B is the intercept.\n    \n    \n    Args:\n        element (str): element to calculate partition coefficient for\n    \n        An (array-like): fraction anorthite content of the plagioclase (X_an)\n    \n        sio2_melt (array-like): SiO2 wt% composition of the melt\n    \n        temp (array-like): temperature in degrees C\n    \n    Returns:\n        dohmen_kd : partition coefficient\n        dohmen_rtlnk : RTln(dohmen_k) in kJ/mol\n        A : slope of regression in dohmen_rtlnk vs X_an space\n        B : intercept of regression in dohmen_rtlnk vs X_an space\n\n\n\nWe’ll begin by importing some data from Lubbers, Kent, and Silva (2024) and plotting it up.\n\n\nShow the code\ndata = pd.read_excel(r\".\\data\\test_data.xlsx\",\n                     sheet_name=\"plagioclase\").set_index('grain')\n\n# specify which grain to use\ngrain = \"MQ3\"\n\n# specify which element to model\nelement = \"Sr\"\n\nresolution = 5.0  # um\n\n# for consistent colors throughout\nobs_color = \"#000000\"  # observed data\n# equilibrium data\ndohmen_color = \"#FF1F5B\"\nan_color = \"#0D4A70\"\ninit_color = \"#A0B1BA\"  # initial profile related data\nbf_color = \"#00CD6C\"\n\n\n# the domain you wish to model diffusion over\n# try to keep this untouched but if there are\n# erroneous ends on your data this will clip them\nstart = 0\nstop = 0\n\n\n# unclipped data for a grain\n# distance\ndist_all = np.arange(0, data.loc[grain, :].shape[0]) * resolution\n# measured trace element information\nte_all = data.loc[grain, element].to_numpy()\nte_unc_all = data.loc[grain, \"{}_se\".format(element)].to_numpy()\n# anorthite\nan_all = data.loc[grain, \"An\"].to_numpy()\nif np.unique(an_all &gt; 1)[0] == True:\n    an_all = an_all / 100\n# clipped data. If above start and stop are 0 they\n# will be the same as the unclipped data. This is fine.\nte = te_all[start: len(te_all) - stop]\nte_unc = te_unc_all[start: len(te_all) - stop]\ndist = dist_all[start: len(te_all) - stop]\nan = an_all[start: len(te_all) - stop]\n\n\n# plot observed data\nfig, ax = plt.subplots(figsize=(4, 4))\n# observed profile and subset\nl1, = ax.plot(\n    dist,\n    te,\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    ms=5,\n    mew=0.75,\n    label=element,\n)\nax.fill_between(dist, te + te_unc, te - te_unc, fc=obs_color, alpha=0.2)\n\nax2 = ax.twinx()\nl2, = ax2.plot(\n    dist,\n    an,\n    c=an_color,\n    marker=\"\",\n    mfc=\"w\",\n    mec=an_color,\n    ms=5,\n    mew=0.75,\n    ls='--',\n    label=\"anorthite\",\n)\nax2.tick_params(axis=\"y\", which=\"both\", colors=an_color)\nax2.set_ylabel(\"X$_{An}$\", c=an_color)\n\nax.legend(handles=[l1, l2], fancybox=True, shadow=True)\n# fig.legend(loc=\"best\")\n\nax.set_ylabel(\"{} [ppm]\".format(element), c=obs_color)\nax.tick_params(axis=\"y\", which=\"both\", colors=obs_color)\nax.set_xlabel(\"Distance ($\\mu$m)\")\n\nax.text(0, 1.03, 'Core', fontsize=20, transform=ax.transAxes)\nax.text(0.8, 1.03, 'Rim', fontsize=20, transform=ax.transAxes)\nplt.show()\n\n\n\n\n\n\n\n\n\nWe then calculate the quasi-equilibrium profile. Later on we will show that no matter how long we run our diffusion model for, the Sr profile will not deviate from the quasi equilibrium situation even though we may be at magmatic temperatures. Below we show:\n\nLeft: our observed Sr profile with respect to the quasi equilibrium profile\nRight: our observed Sr vs XAn data with respect to the quasi equilibrium Sr vs XAn data.\n\nWe also plot a curve (black dashed line) for the equilibrium trace element partitioning at our specified temperature and melt composition.\n\n\nShow the code\nT = 750 #celsius\nT_K = T + 273.15 #kelvin\nR = 8.314 #J/molK\nsio2_melt = 72 #wt%\n\nRTlngamma, gamma, slope, intercept, stats = plag.dohmen_activity_calc(\n    element, an, T, return_regression_stats=True\n)\n\nkd, rtlnk, A, B = plag.plag_kd_calc(\n        element, an, T, method=\"Dohmen\", sio2_melt=sio2_melt)\n\n# range of anorthite compositions to calculate equilibrium curves\nan_partition = np.linspace(0, 1,101)\n\n# Calculated Mg equilibrium\nkd_eq, rtlnk_eq, A_eq, B_eq = plag.plag_kd_calc(\n    element, an_partition, T, method=\"Dohmen\", sio2_melt=sio2_melt\n)\n\n\nc0 = te[-1] * np.exp(-slope*1000/(R*T_K)*an[-1])\neq_prof = c0 * np.exp(slope*1000/(R*T_K)*an)\n\nEq_solid_ave = te[-1] / kd[-1] * kd_eq\n\n\n\nfig,ax = plt.subplots(1,2,figsize = (8,4),layout = 'constrained')\n\nax[0].plot(\n    dist,\n    te,\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    ms=5,\n    mew=0.75,\n    label=f\"{element} observed\",\n)\nax[0].fill_between(dist, te + te_unc, te - te_unc, fc = obs_color, alpha=0.2)\nax[0].plot(dist,eq_prof,lw = 2, color = dohmen_color, label = 'quasi equilibrium')\nax[0].legend(loc = 'best')\n\nax[1].plot(an_partition, Eq_solid_ave, color='k', ls = '--', zorder = 0, label = 'eq. partitioning')\nax[1].plot(an,eq_prof,marker = 'o',ls = '',mfc = 'none',mec = dohmen_color,label = 'quasi equilibrium',zorder = 0)\ns = ax[1].scatter(an, te, c=dist, ec='k', lw=0.75,label = f'{element} observed')\nfig.colorbar(s, ax=ax[1], label='distance ($\\mu$m)')\nax[1].legend(loc = 'upper right')\n\n\nax[0].set_ylabel(f\"{element} [ppm]\")\nax[0].set_xlabel('Distance ($\\mu$m)')\nax[1].set_xlabel('X$_{An}$')\nplt.show()\n\n\n\n\n\n\n\n\n\nNext, we must determine the initial profile. This is probably one of the aspects of plagioclase diffusion modeling that introduces the most uncertainty. The basic premise of this is:\n\ncalculate a “melt equivalent” profile that based on the observed data. This is simply \\(C_l = \\frac{C_s}{K_d}\\) and represents the effective melt composition in equilibrium with the observed data. We make the assumption that some diffusion has occured between crystallization and eruption, and therefore this melt equivalent profile does NOT represent the melt composition at the time of crystallization.\nTo approximate the melt composition at the time of plagioclase formation we take “melt equivalent” profile and simplify it back to a series of two or three discrete compositions that are based off changes in the An profile. Becuase the An component in plagioclase can effectively be treated as stationary in this scenario, it offers a good opportunity to view where changes in melt composition are happening. We then back calculate that simplified melt profile into plagioclase compositions that’s in equilibrium with it to get our initial profile. An overall caveat of this methodology is that it necessitates that not much diffusion has occurred. If significant diffusion has occurred, creating simplified melt profiles off the observed data will not yield a melt profile that reflects the initial melt evolution during crystallization. We however, don’t believe this is the case for our grains, due to the observed positive relationships between Sr and An. In brief, because Sr is compatible in plagioclase, this observed positive relationship generally means that little to no diffusive re-equilibration has occured in plagioclase (e.g., Cooper and Kent 2014). Further evidence to suggest that a positive correlation between Sr and XAn reflects minimal diffusive equilibration is that the quasi equilibrium profile calculated above has a strong negative correlation and as diffusion progresses in the grain from initial profile to quasi equilibrium (shown later) this relationship goes from positive to negative.\n\nIn the case where one is trying to model diffusion for a profile where it is assumed that the profile is close to quasi-equilibrium another method of estimating the initial profile would have to be used (e.g., creating a melt equivalent profile that mimics the shape and magnitude of the An profile changes, creating an initial profile that is effictively a “mirror” to the calculated equilibrium profile). More than any other assumption (and this goes for any study that forward models diffusion in plagioclase) the initial profile is probably the one that introduces the most uncertainty and we realize this, however, based on past reviewer comments in previous manuscripts, it was decided this was a sufficient way to go about it as creating an initial profile that is a simplified version of the observed plagioclase proflie (i.e., creating a solid profile step function) implicitly creates the situation whereby the melt profile would be extremely variable to keep the Sr profile the simplified shape. We do not believe we have the petrologic evidence to create such a melt profile and take an Occam’s Razor approach in this case: a minimum number of input melt compositions is better.\n\n\nShow the code\nmelt_equivalent = te / kd\n\nsimple_liquid = plag.create_stepped_profile(\n    dist,\n    step_start=[20],\n    step_stop=[90],\n    step_left=[105],\n    step_middle=[98],\n    step_right=[145],\n)\n\ninitial_profile = simple_liquid * kd\n\nfig, ax = plt.subplots(1, 3, figsize=(9, 3), layout='constrained')\n\nax[0].plot(dist, an, c=an_color, label='X$_{An}$')\nax[0].set_ylabel('X$_{An}$')\n\nax[1].plot(dist, melt_equivalent, color=obs_color,\n           label='obs. melt equivalent')\nax[1].plot(dist, simple_liquid, color=init_color,\n           ls=\"-.\", lw=2, label=\"simple melt equivalent\")\nax[1].legend(loc='upper left')\n\nax[2].plot(\n    dist,\n    te,\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    ms=5,\n    mew=0.75,\n    label=f\"{element} observed\",\n)\nax[2].fill_between(dist, te + te_unc, te - te_unc, fc=obs_color, alpha=0.2)\nax[2].plot(dist, eq_prof, lw=2, color=dohmen_color, label='quasi equilibrium')\nax[2].plot(dist, initial_profile, color=init_color,\n           ls=\"-.\", lw=2, label=\"initial condition\")\nax[2].legend(loc='best')\n\nax[1].set_ylabel(f\"{element} [ppm]\")\nax[2].set_ylabel(f\"{element} [ppm]\")\n\nfig.supxlabel('Distance ($\\mu$m)')\nplt.show()\n\n\n\n\n\n\n\n\n\nNow that we have our quasi-equilibrium profile calculated, it is time to create our timegrid, calculate the diffusion coefficient, and implement the special halfspace solution to the diffusion equation outlined above. In plag_diff this is easily done by:\n\n\nShow the code\niterations = int(1 * 1e5)\ntimestep = \"tenths\" #iterate every tenth of a year\n\n\n# creating a time grid that is spaced by years\nt = plag.get_tgrid(iterations, timestep)\n\n#diffusion coefficient for every point in the profile\nD = plag.plag_diffusivity(element, an, T_K)\n\n# call the function that does the modeling ove the above numerical\n# solution\ncurves, best_fit_iteration, chi2_array = plag.diffuse_forward_halfspace(\n        initial_profile=initial_profile,\n        observed_profile=te,\n        timegrid=t,\n        diffusivity_profile=D,\n        an_profile=an,\n        slope=slope,\n        distance_profile=dist,\n        temp=T,\n        boundary=\"infinite observed\",\n        local_minima=True,\n    )\n\n\n\n\n\nVisualize the results:\n\n\nShow the code\n#conversion factor to turn iterations to years\nmakeyears = 10\n\nfig,ax = plt.subplots(1,2,figsize = (8,4),layout = 'constrained')\ncompare = [makeyears * 1e2, makeyears * 1e3, makeyears * 1e4,]\ncompare_colors = [\"C3\", \"C4\", \"C5\"]\n\n\nax[0].plot(dist, initial_profile, c = init_color, lw=2, label=\"initial profile\")\nax[0].plot(\n    dist,\n    te,\n    label=\"observed\",\n    c=obs_color,\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    mew=0.75,\n)\nax[0].fill_between(dist, te + te_unc, te - te_unc,fc = obs_color, alpha=0.2)\nax[0].plot(\n    dist, eq_prof, c=dohmen_color, lw=2, ls = '--', label=\"Equilibrium\",)  # boundary conditions\n\nfor i in range(0, len(compare)):\n    ax[0].plot(\n        dist,\n        curves[int(compare[i])],\n        label=\"t = {:.2E} yrs\".format(compare[i] / makeyears),\n        lw=0.75,\n        color=compare_colors[i],\n    )\n    \n\n\nax[0].plot(dist, curves[best_fit_iteration], \"-\", c=bf_color,\n           mec=\"k\", lw=3, label=\"best fit\")\nh, l = ax[0].get_legend_handles_labels()\nfig.legend(h, l, loc=\"upper left\", ncol=len(h)//2, bbox_to_anchor=(0.1, 1.2))\n\n\n# chi-squared plot\n# convert to days\ntdays = t / (t[1] - t[0])\nx_data = tdays / makeyears\nax[1].plot(\n    x_data,\n    chi2_array,\n    \"-k\",\n    lw=2,\n)\n# vertical line at best fit value\nax[1].axvline(\n    best_fit_iteration / makeyears,\n    color=bf_color,\n    label=\"t = {} yrs\".format(np.round(best_fit_iteration / makeyears, 2)),\n    lw=1,\n    ls=\"--\",\n)\nax[1].plot(x_data[best_fit_iteration], chi2_array[best_fit_iteration], mfc=\"w\",\n        marker=\"o\", ls=\"\", mec=bf_color, mew=1)\nax[1].set_xlabel(\"time (yrs)\", fontsize=16)\nax[1].set_ylabel(\"$\\sum{\\chi^2} $\", fontsize=16)\nax[1].set_xscale(\"log\")\nax[1].legend(loc=\"lower left\", title=\"Best Fit\", prop={\"size\": 10})\nax[1].set_yscale(\"log\")\nax[1].set_xlabel(\"Time (yrs)\")\nplt.show()\n\n\n\n\n\n\n\n\n\nNext we’ll deal with model uncertainties. Here we will randomly vary two things for 1000 iterations to see their impact on our diffusion model:\n\nTemperature: this then changes our A value and diffusion coefficient\nOur analytical profile: This reflects uncertainty in our analyses and how it impacts the diffusion model\n\nFor each iteration we will find a best fit diffusion model to the random analytical profile and save it. We’ll then get statistics on this distribution and visualize it.\nWhile technically a change in temperature would change our melt equivalent profile and possibly then our choice of initial profile, this would require a manual choosing of initial condition each iteration of the monte carlo, rendering this sort of exercise not possible. So…for this exercise we leave it the same during each iteration.\nThe plag.diffuse_forward_halfspace function is set up to minimize computation time by being vectorized, however the default is to have the local_minima argument set to True. This forces it to search over the entire timegrid space and calculate a model curve for each value in the timegrid. While quite quick for 1 diffusion model, when we are trying to do 1000 of them, this can unecessarily increase computation time, especially if the best fit is near the front end of the timegrid. By setting local_minima = False the model runs and checks the misfit each iteration. If the misfit is less than the previous iteration the model continues calculating diffusion curves. If the misfit for the current iteration is larger than the previous iteration it stops and marks that as the best fit time. Because we have confirmed above that there are no local minima in our chi-squared vs. time plot, this methodology is safe. Still…This is when you may want to go get a cup of coffee. 1000 iterations can take anywhere from 1-10 minutes. Here we only do 100 to save time in the example.\n\n\nShow the code\nbest_fits = []\niterations = 100  # for example purposes\n\nfor i in tqdm(range(iterations)):\n    T = np.random.normal(750, 20)\n    RTlngamma, gamma, slope, intercept, stats = plag.dohmen_activity_calc(\n        element, an, T, return_regression_stats=True\n    )\n\n    c, b, c2 = plag.diffuse_forward_halfspace(\n        initial_profile=initial_profile,\n        observed_profile=plag.random_profile(te, te_unc),\n        timegrid=t,\n        diffusivity_profile=plag.plag_diffusivity(\n            element=element, an=an, T_K=T + 273.15\n        ),\n        an_profile=an,\n        slope=slope,\n        distance_profile=dist,\n        temp=T,\n        boundary=\"infinite observed\",\n        local_minima=False,\n    )\n    best_fits.append(b)\n\nbest_fits = np.array(best_fits)\n\n\n\n\n\nFinally, we visualize the results of the Monte Carlo simulation and make a summary figure that puts it all together.\n\n\nShow the code\nfig, ax = plt.subplot_mosaic(\n    [[\"prof\", \"an_prof\"], [\"prof\", \"hist\"]],\n    layout=\"constrained\",\n    height_ratios=[2, 1],\n    width_ratios=[3, 2],\n    figsize=(8, 4),\n)\nfs = 10\nms = 5\n\nax[\"prof\"].plot(dist, initial_profile, init_color, lw=2, label=\"initial profile\")\nax[\"prof\"].plot(\n    dist,\n    te,\n    label=\"observed\",\n    c=obs_color,\n    ls=\"\",\n    marker=\"o\",\n    mfc=\"w\",\n    mec=obs_color,\n    mew=0.75,\n    ms=ms,\n)\nax[\"prof\"].fill_between(dist, te + te_unc, te - te_unc, alpha=0.2)\nax[\"prof\"].plot(\n    dist, curves[best_fit_iteration], \"-\", c=bf_color, mec=\"k\", lw=3, label=\"best fit\"\n)\n\nax[\"prof\"].plot(\n    dist, eq_prof, c=dohmen_color, lw=2, label=\"DB14 quasi eq.\"\n)  # boundary conditions\n\n\nax[\"prof\"].set_xlabel(\"Distance ($\\mu$m)\", fontsize=16)\nax[\"prof\"].set_ylabel(f\"{element} [ppm]\", fontsize=16)\n\n\nfig.legend(loc=\"upper left\", ncol=4, bbox_to_anchor=(0.1, 1.1))\n\nax[\"an_prof\"].plot(dist, an, \"k-\", linewidth=1.5)\nax[\"an_prof\"].set_ylabel(\"X$_{An}$\", fontsize=16)\nax[\"an_prof\"].set_xlabel(\"Distance ($\\mu$m)\", fontsize=12)\n\nax[\"hist\"].hist(\n    best_fits / makeyears,\n    facecolor=\"whitesmoke\",\n    edgecolor=\"k\",\n    linestyle=\"--\",\n)\nax[\"hist\"].plot(\n    best_fits.mean() / makeyears,\n    0,\n    marker=\"o\",\n    mec=\"darkgreen\",\n    mfc=bf_color,\n    mew=1.5,\n    clip_on=False,\n    zorder=10,\n)\n# mpl_defaults.left_bottom_axes(ax[\"hist\"])\nax[\"hist\"].set_xlabel(\"best fit time (yrs)\", fontsize=12)\nax[\"hist\"].set_ylabel(\"counts\", fontsize=12)\n\ntransform = \"log\"\n\nif transform:\n    (\n        transform_mc_results,\n        transform_mean,\n        transform_median,\n        transform_low,\n        transform_high,\n    ) = plag.transform_data(best_fits / makeyears, kind=transform)\n\n    ax[\"prof\"].text(\n        0.05,\n        1.03,\n        \"$t_{{mean}}$ = {} yrs\".format(np.round(transform_mean, 2)),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=fs,\n    )\n    ax[\"prof\"].text(\n        0.55,\n        1.03,\n        \"$t_{{95}} = \\pm$ {} ; {}\".format(\n            np.round(transform_mean - transform_low, 2),\n            np.round(transform_high - transform_mean, 2),\n        ),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=fs,\n    )\nelse:\n    ax[\"prof\"].text(\n        0.05,\n        1.03,\n        \"$t_{{mean}}$ = {} yrs\".format(np.round(best_fits.mean(), 2)),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=10,\n    )\n    ax[\"prof\"].text(\n        0.55,\n        1.03,\n        \"$t_{{95}} = \\pm$ {}\".format(np.round(2 * np.std(best_fits), 2)),\n        transform=ax[\"prof\"].transAxes,\n        fontsize=10,\n    )\nplt.show()"
  },
  {
    "objectID": "numerical_modeling_walkthrough.html#references",
    "href": "numerical_modeling_walkthrough.html#references",
    "title": "Modeling Diffusion in Volcanic Minerals",
    "section": "References",
    "text": "References\n\n\nBradshaw, Richard W, and Adam JR Kent. 2017. “The Analytical Limits of Modeling Short Diffusion Timescales.” Chemical Geology 466: 667–77. https://doi.org/10.1016/j.chemgeo.2017.07.018.\n\n\nChakraborty, Sumit. 2010. “Diffusion Coefficients in Olivine, Wadsleyite and Ringwoodite.” Reviews in Mineralogy and Geochemistry 72 (1): 603–39. https://doi.org/10.2138/rmg.2010.72.13.\n\n\nCooper, Kari M, and Adam JR Kent. 2014. “Rapid Remobilization of Magmatic Crystals Kept in Cold Storage.” Nature 506 (7489): 480–83. https://doi.org/10.1038/nature12991.\n\n\nCosta, F, S Chakraborty, and R Dohmen. 2003. “Diffusion Coupling Between Trace and Major Elements and a Model for Calculation of Magma Residence Times Using Plagioclase.” Geochimica Et Cosmochimica Acta 67 (12): 2189–2200. https://doi.org/10.1016/S0016-7037(02)01345-5.\n\n\nCosta, Fidel, Ralf Dohmen, and Sumit Chakraborty. 2008. “Time Scales of Magmatic Processes from Modeling the Zoning Patterns of Crystals.” Reviews in Mineralogy and Geochemistry 69 (1): 545–94. https://doi.org/10.2138/rmg.2008.69.14.\n\n\nCrank, John. 1979. The Mathematics of Diffusion. Oxford university press.\n\n\nDohmen, Ralf, and Jon Blundy. 2014. “A Predictive Thermodynamic Model for Element Partitioning Between Plagioclase and Melt as a Function of Pressure, Temperature and Composition.” American Journal of Science 314 (9): 1319–72. https://doi.org/10.2475/09.2014.04.\n\n\nDohmen, Ralf, Kathrin Faak, and Jon D Blundy. 2017. “Chronometry and Speedometry of Magmatic Processes Using Chemical Diffusion in Olivine, Plagioclase and Pyroxenes.” Reviews in Mineralogy and Geochemistry 83 (1): 535–75. https://doi.org/10.2138/rmg.2017.83.16.\n\n\nDohmen, Ralf, Jan H Ter Heege, Hans-Werner Becker, and Sumit Chakrabortrty. 2016. “Fe-Mg Interdiffusion in Orthopyroxene.” American Mineralogist 101 (10): 2210–21. https://doi.org/10.2138/am-2016-5815.\n\n\nFick, Adolph. 1855. “V. On Liquid Diffusion.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 10 (63): 30–39. https://doi.org/10.1080/14786445508641925.\n\n\nLubbers, Jordan, Adam JR Kent, and Shanaka de Silva. 2024. “Constraining Magma Storage Conditions of the Toba Magmatic System: A Plagioclase and Amphibole Perspective.” Contributions to Mineralogy and Petrology 179 (2): 12. https://doi.org/10.1007/s00410-023-02089-7.\n\n\nRuth, DCS, and F Costa. 2021. “A Petrological and Conceptual Model of Mayon Volcano (Philippines) as an Example of an Open-Vent Volcano.” Bulletin of Volcanology 83 (10): 62. https://doi.org/10.1007/s00445-021-01486-9.\n\n\nTaylor, John R. 2022. An Introduction to Error Analysis: The Study of Uncertainties in Physical Measurements, Third Edition. University Science Books."
  }
]